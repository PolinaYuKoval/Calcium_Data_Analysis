{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455b3ba7-7f53-4299-9012-53c8a304b82d",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- adjust links according to your file system\n",
    "- check the existing folders to save the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfafd523-f334-4b2e-bf8f-6abffdd4b08a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee50b826-1e7d-496a-9e8a-0f4df32e7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "\n",
    "import peakutils \n",
    "\n",
    "import scipy\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "import scipy.io\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import norm\n",
    "\n",
    "import os\n",
    "\n",
    "import tifffile as tiff\n",
    "from tifffile import imshow\n",
    "\n",
    "from ipywidgets import interactive, fixed, IntSlider, Checkbox\n",
    "\n",
    "import skimage.io as skio\n",
    "from skimage import exposure\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_triangle, threshold_li, gaussian\n",
    "from skimage.morphology import remove_small_objects, binary_dilation, binary_erosion, label\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "import cv2\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from ipywidgets import interactive, IntSlider\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e144e6c7-e554-4602-95d0-d5d25ff369e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd8a56e4-ec60-4db1-91fc-76862b06e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfu_to_tif(cfu_link, cfu_global, path_to_save):\n",
    "    \"\"\"\n",
    "    Converts a CFU MATLAB data to a TIFF image and saves it.\n",
    "    \"\"\"\n",
    "    mat = scipy.io.loadmat(cfu_link)\n",
    "    os.makedirs(path_to_save, exist_ok=True)\n",
    "    cfu_i = mat[cfu_global]\n",
    "    cfu_info_normalized = (cfu_i / np.max(cfu_i) * 255).astype(np.uint8)\n",
    "    path_to_save = os.path.join(path_to_save, cfu_global + '.tiff')\n",
    "    image = Image.fromarray(cfu_info_normalized)\n",
    "    image.save(path_to_save)\n",
    "    return path_to_save\n",
    "\n",
    "def cfu_to_tif_global(cfu_link, path_to_save, cfu_global = 'cfuInfo1', index_2=2):\n",
    "    \"\"\"\n",
    "    Converts a CFU MATLAB data to a TIFF image and saves it.\n",
    "    \"\"\"\n",
    "    mat = scipy.io.loadmat(cfu_link)\n",
    "    os.makedirs(path_to_save, exist_ok=True)\n",
    "    df_test = {}\n",
    "    mask_name = 'Mask_'\n",
    "    for i in range(mat[cfu_global].shape[0]):\n",
    "        a = Image.fromarray((mat['cfuInfo1'][i][index_2] / np.max( mat['cfuInfo1'][i][index_2]) * 255).astype(np.uint8))\n",
    "        df_test['Mask_' + str(i)] = a\n",
    "        path = os.path.join(path_to_save, cfu_global + mask_name + str(i) + '.tiff')\n",
    "        image = a\n",
    "        image.save(path)\n",
    "    return \n",
    "def get_data_global(cfu_link, path_to_save, cfu_global = 'cfuInfo1'):\n",
    "    \"\"\"\n",
    "    Converts a CFU MATLAB data to a TIFF image and saves it.\n",
    "    \"\"\"\n",
    "    mat = scipy.io.loadmat(cfu_link)\n",
    "    os.makedirs(path_to_save, exist_ok=True)\n",
    "    df_data = {}\n",
    "    df_data_df = {}\n",
    "    mask_name = 'Mask_'\n",
    "    for i in range(mat[cfu_global].shape[0]):\n",
    "        df_data['Mask_' + str(i)] = mat['cfuInfo1'][i][4][0]\n",
    "        df_data_df['Mask_' + str(i)] = mat['cfuInfo1'][i][5][0]\n",
    "    #df_data = pd.DataFrame(df_data)\n",
    "    #df_data_df = pd.DataFrame(df_data_df)\n",
    "    return df_data, df_data_df\n",
    "def df_trans_ren(df, global_coef):\n",
    "    \"\"\"\n",
    "    Transposes a DataFrame and renames columns with a prefix.\n",
    "    \"\"\"\n",
    "    df_transposed = df.T\n",
    "    df_transposed.columns = [global_coef + f\"{i+1}\" for i in range(df_transposed.shape[1])]\n",
    "    return df_transposed\n",
    "\n",
    "\n",
    "def calculate_baseline(df, sigma=10, deg=5):\n",
    "    \"\"\"\n",
    "    Calculates baselines for each column in the DataFrame.\n",
    "    \"\"\"\n",
    "    baselines = {}\n",
    "    for col in df.columns:\n",
    "        smoothed_data = gaussian_filter(df[col].values, sigma=sigma)\n",
    "        baselines[col] = peakutils.baseline(smoothed_data, deg=deg)\n",
    "    return pd.DataFrame(baselines)\n",
    "\n",
    "def plot_and_save(df, baselines, output_dir, combined_filename=\"all_cfus_combined_graph.html\"):\n",
    "    \"\"\"\n",
    "    Plots and saves individual CFU graphs and a combined graph.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig_combined = go.Figure()\n",
    "    for col in df.columns:\n",
    "        cfu_data = df[col].values\n",
    "        baseline = baselines[col].values\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=cfu_data, mode='lines', name=f\"CFU {col}\", line=dict(color=\"blue\")))\n",
    "        fig.add_trace(go.Scatter(y=baseline, mode='lines', name=f\"Baseline {col}\", line=dict(color=\"red\", dash=\"dash\")))\n",
    "        fig.update_layout(\n",
    "            title=f\"Graph for CFU {col} with Baseline\",\n",
    "            xaxis_title=\"Index\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        output_path = os.path.join(output_dir, f\"cfu_{col}_graph.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved interactive graph for CFU {col} as {output_path}\")\n",
    "        fig_combined.add_trace(go.Scatter(y=cfu_data, mode='lines', name=f\"CFU {col}\"))\n",
    "        fig_combined.add_trace(go.Scatter(y=baseline, mode='lines', name=f\"Baseline {col}\", line=dict(dash=\"dash\")))\n",
    "    combined_output_path = os.path.join(output_dir, combined_filename)\n",
    "    fig_combined.update_layout(\n",
    "        title=\"Combined Graph for All CFUs with Baselines\",\n",
    "        xaxis_title=\"Index\",\n",
    "        yaxis_title=\"Intensity\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_combined.write_html(combined_output_path)\n",
    "    print(f\"Saved combined graph as {combined_output_path}\")\n",
    "\n",
    "def detect_peaks(df, height=None, prominence=None, distance=None):\n",
    "    \"\"\"\n",
    "    Detects peaks in each column of a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with Delta F/F data.\n",
    "        height (float, optional): Minimum height of peaks.\n",
    "        prominence (float, optional): Minimum prominence of peaks.\n",
    "        distance (int, optional): Minimum distance between peaks.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with column names as keys and detected peak indices as values.\n",
    "        pd.DataFrame: A DataFrame with the number of peaks detected for each CFU.\n",
    "    \"\"\"\n",
    "    peak_indices = {}\n",
    "    peak_counts = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        data = df[col].values\n",
    "        peaks, _ = find_peaks(data, height=height, prominence=prominence, distance=distance)\n",
    "        peak_indices[col] = peaks\n",
    "        peak_counts[col] = len(peaks)\n",
    "    peak_counts_df = pd.DataFrame(list(peak_counts.items()), columns=[\"CFU\", \"Peak Count\"])\n",
    "    peak_counts_df.set_index(\"CFU\", inplace=True)\n",
    "    \n",
    "    return peak_indices, peak_counts_df\n",
    "\n",
    "def plot_peaks(df, peak_indices, output_dir):\n",
    "    \"\"\"\n",
    "    Plots data with detected peaks for each CFU.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        data = df[col].values\n",
    "        peaks = peak_indices[col]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=data, mode='lines', name=f\"CFU {col}\"))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=peaks, y=data[peaks], mode='markers', name=f\"Peaks {col}\",\n",
    "            marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Detected Peaks for CFU {col}\",\n",
    "            xaxis_title=\"Index\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        output_path = os.path.join(output_dir, f\"cfu_{col}_peaks.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved peak detection graph for CFU {col} to {output_path}\")\n",
    "\n",
    "def low_pass_filter(data, cutoff, fs, order=4):\n",
    "    \"\"\"\n",
    "    Apply a low-pass Butterworth filter to the data.\n",
    "\n",
    "    Parameters:\n",
    "        data (np.ndarray): The input data to filter.\n",
    "        cutoff (float): The cutoff frequency in Hz.\n",
    "        fs (float): The sampling frequency in Hz.\n",
    "        order (int): The order of the filter.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The filtered data.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs  # Nyquist frequency\n",
    "    normal_cutoff = cutoff / nyquist  # Normalize cutoff frequency\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)  # Design filter\n",
    "    filtered_data = filtfilt(b, a, data)  # Apply filter\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def detect_peaks_on_smoothed_data(df, fs=30, cutoff=5, height=None, prominence=None, distance=None):\n",
    "    \"\"\"\n",
    "    Detect peaks on smoothed data using a low-pass filter for noise reduction.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with original Delta F/F data.\n",
    "        fs (float): Sampling frequency in Hz (default 30 Hz).\n",
    "        cutoff (float): Cutoff frequency for the low-pass filter in Hz (default 5 Hz).\n",
    "        height (float, optional): Minimum height of peaks.\n",
    "        prominence (float, optional): Minimum prominence of peaks.\n",
    "        distance (int, optional): Minimum distance between peaks.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with column names as keys and detected peak indices as values.\n",
    "        dict: A dictionary with column names as keys and smoothed data as values.\n",
    "        pd.DataFrame: A DataFrame with the number of peaks detected for each CFU.\n",
    "    \"\"\"\n",
    "    peak_indices = {}\n",
    "    smoothed_data_dict = {}\n",
    "    peak_counts = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        smoothed_data = low_pass_filter(df[col].values, cutoff=cutoff, fs=fs)\n",
    "        smoothed_data_dict[col] = smoothed_data\n",
    "        peaks, _ = find_peaks(smoothed_data, height=height, prominence=prominence, distance=distance)\n",
    "        peak_indices[col] = peaks\n",
    "        peak_counts[col] = len(peaks)\n",
    "    peak_counts_df = pd.DataFrame(list(peak_counts.items()), columns=[\"CFU\", \"Peak Count\"])\n",
    "    peak_counts_df.set_index(\"CFU\", inplace=True)\n",
    "    \n",
    "    return peak_indices, smoothed_data_dict, peak_counts_df\n",
    "\n",
    "def plot_peaks_on_smoothed_data_with_baseline(df, smoothed_data_dict, peak_indices, baseline_dict, output_dir, fps):\n",
    "    \"\"\"\n",
    "    Plots smoothed data, original df, baseline, and detected peaks for each CFU in seconds.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original data for reference.\n",
    "        smoothed_data_dict (dict): Dictionary of smoothed data.\n",
    "        peak_indices (dict): Dictionary of detected peaks.\n",
    "        baseline_dict (dict): Dictionary of baseline values for each CFU.\n",
    "        output_dir (str): Directory to save the plots.\n",
    "        fps (float): Frames per second of the data.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig_combined = go.Figure()\n",
    "\n",
    "    for col in df.columns:\n",
    "        original_data = df[col].values\n",
    "        smoothed_data = smoothed_data_dict[col]\n",
    "        peaks = peak_indices[col]\n",
    "        baseline = baseline_dict[col]\n",
    "        time_seconds = np.arange(len(original_data)) / fps  # Convert frame numbers to seconds\n",
    "\n",
    "        # Create the plot\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=time_seconds, y=original_data, mode='lines', name=f\"Original CFU {col}\", line=dict(color=\"blue\")))\n",
    "        fig.add_trace(go.Scatter(x=time_seconds, y=smoothed_data, mode='lines', name=f\"Smoothed CFU {col}\", line=dict(color=\"green\")))\n",
    "        fig.add_trace(go.Scatter(x=time_seconds, y=baseline, mode='lines', name=f\"Baseline {col}\", line=dict(color=\"orange\", dash='dash')))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=time_seconds[peaks], y=smoothed_data[peaks], mode='markers', name=f\"Peaks {col}\",\n",
    "            marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Smoothed Data with Detected Peaks for CFU {col}\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"cfu_{col}_smoothed_peaks.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved peak detection graph for CFU {col} to {output_path}\")\n",
    "\n",
    "        # Add to combined plot\n",
    "        fig_combined.add_trace(go.Scatter(x=time_seconds, y=smoothed_data, mode='lines', name=f\"Smoothed CFU {col}\"))\n",
    "        fig_combined.add_trace(go.Scatter(\n",
    "            x=time_seconds[peaks], y=smoothed_data[peaks], mode='markers', name=f\"Peaks {col} ({len(peaks)})\"\n",
    "        ))\n",
    "        fig_combined.add_trace(go.Scatter(x=time_seconds, y=baseline, mode='lines', name=f\"Baseline {col} ({col})\"))\n",
    "\n",
    "    combined_output_path = os.path.join(output_dir, \"all_cfus_smoothed_peaks_combined.html\")\n",
    "    fig_combined.update_layout(\n",
    "        title=\"Smoothed Data with Detected Peaks for All CFUs\",\n",
    "        xaxis_title=\"Time (s)\",\n",
    "        yaxis_title=\"Intensity\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_combined.write_html(combined_output_path)\n",
    "    print(f\"Saved combined peak detection graph to {combined_output_path}\")\n",
    "\n",
    "\n",
    "def plot_peak_density_per_cfu(peak_indices, fs, output_dir=\"peak_density_plots\", bins=30):\n",
    "    \"\"\"\n",
    "    Plots the density of detected peaks per second for each CFU and saves as HTML.\n",
    "\n",
    "    Parameters:\n",
    "        peak_indices (dict): A dictionary with CFU names as keys and detected peak indices as values.\n",
    "        fs (float): Sampling frequency in Hz.\n",
    "        output_dir (str): Directory to save the HTML plots.\n",
    "        bins (int): Number of bins for the histogram.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "    for cfu, indices in peak_indices.items():\n",
    "        # Convert peak indices to time (seconds)\n",
    "        peak_times = np.array(indices) / fs\n",
    "\n",
    "        # Create histogram bins\n",
    "        peak_counts, bin_edges = np.histogram(peak_times, bins=bins)\n",
    "\n",
    "        # Create the Plotly bar plot\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=bin_edges[:-1],\n",
    "            y=peak_counts,\n",
    "            width=(bin_edges[1] - bin_edges[0]),\n",
    "            marker=dict(color=\"blue\", opacity=0.7),\n",
    "            name=\"Peak Density\"\n",
    "        ))\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f\"Peak Density for {cfu}\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis_title=\"Peak Density (Peaks per Bin)\",\n",
    "            template=\"plotly_white\",\n",
    "            bargap=0.1\n",
    "        )\n",
    "\n",
    "        # Save the plot as HTML\n",
    "        output_path = os.path.join(output_dir, f\"peak_density_{cfu}.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved peak density plot for {cfu} to {output_path}\")\n",
    "        \n",
    "\n",
    "def calculate_intensities(tiff_file, mask_folder, output_csv):\n",
    "    \"\"\"\n",
    "    Calculate frame-wise intensities for each mask and save as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        tiff_file (str): Path to the multi-frame TIFF file.\n",
    "        mask_folder (str): Path to the folder containing mask files as TIFFs.\n",
    "        output_csv (str): Path to save the intensity DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing frame-wise intensities for each mask.\n",
    "    \"\"\"\n",
    "    with tiff.TiffFile(tiff_file) as tif:\n",
    "        tiff_data = tif.asarray()\n",
    "\n",
    "    print(f\"Loaded TIFF with shape {tiff_data.shape} (frames, height, width)\")\n",
    "    num_frames = tiff_data.shape[0]\n",
    "    intensity_data = pd.DataFrame(index=range(num_frames))\n",
    "    for mask_file in os.listdir(mask_folder):\n",
    "        if not mask_file.endswith('.tiff'):\n",
    "            continue\n",
    "        mask_path = os.path.join(mask_folder, mask_file)\n",
    "        with tiff.TiffFile(mask_path) as mask_tif:\n",
    "            mask = mask_tif.asarray().astype(bool)\n",
    "        if mask.shape != tiff_data.shape[1:]:\n",
    "            raise ValueError(f\"Mask {mask_file} shape {mask.shape} does not match TIFF shape {tiff_data.shape[1:]}\")\n",
    "        frame_intensities = [np.mean(frame[mask]) for frame in tiff_data]\n",
    "        mask_name = os.path.splitext(mask_file)[0]\n",
    "        intensity_data[mask_name] = frame_intensities\n",
    "    intensity_data.to_csv(output_csv)\n",
    "    print(f\"Saved intensity data to {output_csv}\")\n",
    "\n",
    "    return intensity_data\n",
    "    \n",
    "def crop_tiff_dimensions(tiff_data, crop_pixels=5):\n",
    "    \"\"\"\n",
    "    Crop the second and third dimensions (height and width) of a TIFF file.\n",
    "\n",
    "    Parameters:\n",
    "        tiff_data (np.ndarray): Original TIFF data (frames, height, width).\n",
    "        crop_pixels (int): Number of pixels to crop from each side.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Cropped TIFF data.\n",
    "    \"\"\"\n",
    "    return tiff_data[:, crop_pixels:-crop_pixels, crop_pixels:-crop_pixels]\n",
    "\n",
    "\n",
    "def calculate_dff(intensity_data):\n",
    "    \"\"\"\n",
    "    Calculate Delta F/F for the given intensity data using column-wise minimum as baseline.\n",
    "\n",
    "    Parameters:\n",
    "        intensity_data (pd.DataFrame): Frame-wise intensity data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing Delta F/F values.\n",
    "    \"\"\"\n",
    "    baselines = intensity_data.min(axis=0)\n",
    "    dff = (intensity_data - baselines) / baselines\n",
    "    return dff\n",
    "\n",
    "'''\n",
    "def detect_peaks(dff_data, height=None, prominence=None, distance=None):\n",
    "    \"\"\"\n",
    "    Detect peaks in Delta F/F data for each mask.\n",
    "\n",
    "    Parameters:\n",
    "        dff_data (pd.DataFrame): Delta F/F DataFrame.\n",
    "        height (float, optional): Minimum peak height.\n",
    "        prominence (float, optional): Minimum prominence of peaks.\n",
    "        distance (int, optional): Minimum distance between peaks.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with column names as keys and detected peak indices as values.\n",
    "    \"\"\"\n",
    "    peak_indices = {}\n",
    "\n",
    "    for col in dff_data.columns:\n",
    "        # Detect peaks\n",
    "        peaks, _ = find_peaks(dff_data[col].values, height=height, prominence=prominence, distance=distance)\n",
    "        peak_indices[col] = peaks\n",
    "\n",
    "    return peak_indices\n",
    "'''\n",
    "\n",
    "def plot_dff_and_peaks(dff_data, peak_indices, output_dir):\n",
    "    \"\"\"\n",
    "    Plot Delta F/F data and detected peaks for each mask.\n",
    "\n",
    "    Parameters:\n",
    "        dff_data (pd.DataFrame): Delta F/F DataFrame.\n",
    "        peak_indices (dict): Dictionary of detected peak indices.\n",
    "        output_dir (str): Directory to save the plots.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig_combined = go.Figure()\n",
    "\n",
    "    for col in dff_data.columns:\n",
    "        dff_values = dff_data[col].values\n",
    "        peaks = peak_indices[col]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=dff_values, mode='lines', name=f\"Delta F/F {col}\", line=dict(color=\"blue\")))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=peaks, y=dff_values[peaks], mode='markers', name=f\"Peaks {col}\",\n",
    "            marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Delta F/F and Peaks for {col}\",\n",
    "            xaxis_title=\"Frame\",\n",
    "            yaxis_title=\"Delta F/F\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        fig.write_html(os.path.join(output_dir, f\"{col}_dff_peaks.html\"))\n",
    "        fig_combined.add_trace(go.Scatter(y=dff_values, mode='lines', name=f\"Delta F/F {col}\"))\n",
    "        fig_combined.add_trace(go.Scatter(\n",
    "            x=peaks, y=dff_values[peaks], mode='markers', name=f\"Peaks {col} ({len(peaks)})\"\n",
    "        ))\n",
    "    combined_output_path = os.path.join(output_dir, \"combined_dff_peaks.html\")\n",
    "    fig_combined.update_layout(\n",
    "        title=\"Combined Delta F/F and Peaks for All Masks\",\n",
    "        xaxis_title=\"Frame\",\n",
    "        yaxis_title=\"Delta F/F\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_combined.write_html(combined_output_path)\n",
    "    print(f\"Saved combined Delta F/F and peaks plot to {combined_output_path}\")\n",
    "\n",
    "def plot_and_save_intensities(intensity_data, smoothed_data, peak_indices, output_dir):\n",
    "    \"\"\"\n",
    "    Plot and save intensity and peak detection results.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig_combined = go.Figure()\n",
    "\n",
    "    for col in intensity_data.columns:\n",
    "        original_data = intensity_data[col].values\n",
    "        smoothed = smoothed_data[col]\n",
    "        peaks = peak_indices[col]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=original_data, mode='lines', name=f\"Original {col}\", line=dict(color=\"blue\")))\n",
    "        fig.add_trace(go.Scatter(y=smoothed, mode='lines', name=f\"Smoothed {col}\", line=dict(color=\"green\")))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=peaks, y=smoothed[peaks], mode='markers', name=f\"Peaks {col}\",\n",
    "            marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Intensity and Peaks for {col}\",\n",
    "            xaxis_title=\"Frame\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        fig.write_html(os.path.join(output_dir, f\"{col}_peaks.html\"))\n",
    "        fig_combined.add_trace(go.Scatter(y=smoothed, mode='lines', name=f\"Smoothed {col}\"))\n",
    "        fig_combined.add_trace(go.Scatter(\n",
    "            x=peaks, y=smoothed[peaks], mode='markers', name=f\"Peaks {col} ({len(peaks)})\"\n",
    "        ))\n",
    "    combined_output_path = os.path.join(output_dir, \"combined_peaks.html\")\n",
    "    fig_combined.update_layout(\n",
    "        title=\"Combined Intensity and Peaks for All Masks\",\n",
    "        xaxis_title=\"Frame\",\n",
    "        yaxis_title=\"Intensity\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_combined.write_html(combined_output_path)\n",
    "    print(f\"Saved combined intensity and peaks plot to {combined_output_path}\")\n",
    "\n",
    "def save_cfu_analysis_with_report_v2(\n",
    "    df, smoothed_data_dict, baseline_dict, peak_indices, output_dir,\n",
    "    link_folder, link_file_mat, link_save,\n",
    "    sigma_value, deg_value, fs_value, height_value, prominence_value, distance_value\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves the CFU analysis results to CSV files and generates a detailed TXT report.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original CFU DataFrame.\n",
    "        smoothed_data_dict (dict): Dictionary containing smoothed data for each CFU.\n",
    "        baseline_dict (dict): Dictionary containing baseline data for each CFU.\n",
    "        peak_indices (dict): Dictionary containing indices of detected peaks for each CFU.\n",
    "        output_dir (str): Directory to save the CSV files and report.\n",
    "        link_folder (str): Folder containing the data.\n",
    "        link_file_mat (str): Path to the original MAT file.\n",
    "        link_save (str): Folder where files are saved.\n",
    "        sigma_value (float): Smoothing sigma value.\n",
    "        deg_value (int): Degree of baseline correction.\n",
    "        fs_value (float): Frames per second of the data.\n",
    "        height_value (float): Minimum peak height for detection.\n",
    "        prominence_value (float): Minimum peak prominence for detection.\n",
    "        distance_value (int): Minimum distance between peaks.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cfu_analysis_df = pd.DataFrame()\n",
    "\n",
    "    # Generate the main analysis DataFrame\n",
    "    for cfu in df.columns:\n",
    "        original_data = df[cfu]\n",
    "        smoothed_data = smoothed_data_dict[cfu]\n",
    "        baseline_data = baseline_dict[cfu]\n",
    "        peak_mask = np.zeros(len(smoothed_data), dtype=int)\n",
    "        peak_mask[peak_indices[cfu]] = 1  # Mark peaks as 1, others as 0\n",
    "\n",
    "        cfu_data = pd.DataFrame({\n",
    "            \"CFU\": cfu,\n",
    "            \"Original CFU Data\": original_data,\n",
    "            \"Smoothed CFU Data\": smoothed_data,\n",
    "            \"Baseline CFU Data\": baseline_data,\n",
    "            \"Detected Peaks (Smoothed)\": peak_mask\n",
    "        })\n",
    "        cfu_analysis_df = pd.concat([cfu_analysis_df, cfu_data], ignore_index=True)\n",
    "\n",
    "    # Save the main CFU analysis DataFrame\n",
    "    cfu_analysis_csv_path = os.path.join(output_dir, \"cfu_analysis.csv\")\n",
    "    cfu_analysis_df.to_csv(cfu_analysis_csv_path, index=False)\n",
    "    print(f\"Saved CFU analysis to {cfu_analysis_csv_path}\")\n",
    "\n",
    "    # Generate the peaks summary DataFrame with counts\n",
    "    peaks_data = []\n",
    "    for cfu, indices in peak_indices.items():\n",
    "        peaks_data.append({\"CFU\": cfu, \"Detected Peak Count\": len(indices)})\n",
    "\n",
    "    peaks_df = pd.DataFrame(peaks_data)\n",
    "\n",
    "    # Save the peaks summary DataFrame\n",
    "    peaks_csv_path = os.path.join(output_dir, \"detected_peaks_summary.csv\")\n",
    "    peaks_df.to_csv(peaks_csv_path, index=False)\n",
    "    print(f\"Saved detected peaks summary to {peaks_csv_path}\")\n",
    "\n",
    "    # Generate a report as a TXT file\n",
    "    report_path = os.path.join(output_dir, \"analysis_report.txt\")\n",
    "    with open(report_path, \"w\") as report_file:\n",
    "        report_file.write(\"Analysis Report\\n\")\n",
    "        report_file.write(\"=\" * 40 + \"\\n\\n\")\n",
    "\n",
    "        # Write metadata\n",
    "        report_file.write(\"Links and Paths:\\n\")\n",
    "        report_file.write(f\"Data Folder: {link_folder}\\n\")\n",
    "        report_file.write(f\"MAT File: {link_file_mat}\\n\")\n",
    "        report_file.write(f\"Save Folder: {link_save}\\n\\n\")\n",
    "\n",
    "        # Write coefficients\n",
    "        report_file.write(\"Coefficients Used:\\n\")\n",
    "        report_file.write(f\"Smoothing Sigma Value: {sigma_value}\\n\")\n",
    "        report_file.write(f\"Baseline Degree: {deg_value}\\n\")\n",
    "        report_file.write(f\"Frames Per Second (FPS): {fs_value}\\n\")\n",
    "        report_file.write(f\"Peak Detection Height: {height_value}\\n\")\n",
    "        report_file.write(f\"Peak Detection Prominence: {prominence_value}\\n\")\n",
    "        report_file.write(f\"Peak Detection Distance: {distance_value}\\n\\n\")\n",
    "\n",
    "        # Write FPS and DataFrame length\n",
    "        report_file.write(f\"Total Length of Data (Mask_0): {len(df['Mask_0'])}\\n\")\n",
    "\n",
    "        # Write peaks summary\n",
    "        report_file.write(\"\\nNumber of Peaks per Mask:\\n\")\n",
    "        for cfu, indices in peak_indices.items():\n",
    "            report_file.write(f\"- {cfu}: {len(indices)} peaks\\n\")\n",
    "\n",
    "        # Write file paths\n",
    "        report_file.write(\"\\nFiles Saved:\\n\")\n",
    "        report_file.write(f\"- CFU Analysis: {cfu_analysis_csv_path}\\n\")\n",
    "        report_file.write(f\"- Peaks Summary: {peaks_csv_path}\\n\")\n",
    "\n",
    "        # Add date and time of analysis\n",
    "        report_file.write(\"\\nDate and Time of Analysis:\\n\")\n",
    "        report_file.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "        # Add output folder location\n",
    "        report_file.write(\"\\nOutput Folder:\\n\")\n",
    "        report_file.write(f\"{output_dir}\\n\")\n",
    "\n",
    "    print(f\"Saved analysis report to {report_path}\")\n",
    "\n",
    "def plot_combined_smoothed_and_peak_density(\n",
    "    df, smoothed_data_dict, peak_indices, fps, height_value, prominence_value, distance_value, sigma_value, output_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the smoothed data with detected peaks, and aligns it with a barplot of peak density.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original Delta F/F data.\n",
    "        smoothed_data_dict (dict): Dictionary of smoothed data for each CFU.\n",
    "        peak_indices (dict): Dictionary of detected peaks for each CFU.\n",
    "        fps (float): Sampling frequency in Hz.\n",
    "        height_value (float): Minimum height of peaks for detection.\n",
    "        prominence_value (float): Minimum prominence of peaks.\n",
    "        distance_value (int): Minimum distance between peaks.\n",
    "        sigma_value (float): Smoothing coefficient.\n",
    "        output_path (str): Path to save the combined plot.\n",
    "    \"\"\"\n",
    "    for cfu in df.columns:\n",
    "        # Original data, smoothed data, and peaks\n",
    "        original_data = df[cfu].values\n",
    "        smoothed_data = smoothed_data_dict[cfu]\n",
    "        peaks = peak_indices[cfu]\n",
    "        time_seconds = np.arange(len(original_data)) / fps  # Convert frame numbers to seconds\n",
    "\n",
    "        # Calculate peak density\n",
    "        peak_times = np.array(peaks) / fps\n",
    "        bin_edges = np.arange(0, time_seconds[-1] + 1, 1)  # Align bins to time axis\n",
    "        peak_counts, bin_edges = np.histogram(peak_times, bins=bin_edges)\n",
    "\n",
    "        # Create subplots\n",
    "        fig = sp.make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.1,\n",
    "            row_heights=[0.7, 0.3],\n",
    "            subplot_titles=(f\"Smoothed Data with Peaks for {cfu}\", \"Peak Density\")\n",
    "        )\n",
    "\n",
    "        # Add smoothed data and peaks to the first subplot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=time_seconds, y=original_data, mode='lines', name=\"Original Data\", line=dict(color=\"blue\", width=1)),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=time_seconds, y=smoothed_data, mode='lines', name=\"Smoothed Data\", line=dict(color=\"green\", width=2)),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=time_seconds[peaks], y=smoothed_data[peaks], mode='markers', name=\"Detected Peaks\",\n",
    "                       marker=dict(color='red', size=8)),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        # Add barplot of peak density to the second subplot\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=bin_edges[:-1], y=peak_counts, width=1,  # Ensure bar width aligns with bins\n",
    "                name=\"Peak Density\", marker=dict(color=\"blue\", opacity=0.7)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f\"Combined Smoothed Data and Peak Density for {cfu}\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis=dict(title=\"Intensity\"),\n",
    "            yaxis2=dict(title=\"Peak Density (Peaks per Bin)\"),\n",
    "            template=\"plotly_white\",\n",
    "            legend_title=\"Input Parameters\",\n",
    "            annotations=[\n",
    "                dict(\n",
    "                    text=(\n",
    "                        f\"<b>Parameters:</b><br>\"\n",
    "                        f\"FPS: {fps}<br>\"\n",
    "                        f\"Height: {height_value}<br>\"\n",
    "                        f\"Prominence: {prominence_value}<br>\"\n",
    "                        f\"Distance: {distance_value}<br>\"\n",
    "                        f\"Smoothing Sigma: {sigma_value}\"\n",
    "                    ),\n",
    "                    x=1.1, y=1.2, showarrow=False, xref=\"paper\", yref=\"paper\", align=\"left\"\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Save the plot\n",
    "        fig.write_html(output_path + f\"/combined_smoothed_peak_density_{cfu}.html\")\n",
    "        print(f\"Saved combined plot for {cfu} to {output_path}\")\n",
    "\n",
    "def compare_peak_times(peak_indices, tolerance_frames, fps, output_path):\n",
    "    \"\"\"\n",
    "    Compares whether different masks (CFUs) have peaks at the same time within a given tolerance\n",
    "    and generates a heatmap showing the overlap.\n",
    "\n",
    "    Parameters:\n",
    "        peak_indices (dict): A dictionary with CFU names as keys and detected peak indices as values.\n",
    "        tolerance_frames (int): Tolerance around the peak for comparison (in frames).\n",
    "        fps (float): Frames per second, used to annotate the heatmap with time in seconds.\n",
    "        output_path (str): Path to save the heatmap HTML file.\n",
    "    \"\"\"\n",
    "    cfus = list(peak_indices.keys())\n",
    "    num_cfus = len(cfus)\n",
    "    overlap_matrix = np.zeros((num_cfus, num_cfus), dtype=int)\n",
    "    for i, cfu_1 in enumerate(cfus):\n",
    "        for j, cfu_2 in enumerate(cfus):\n",
    "            if i <= j:  # Only compute upper triangle (matrix is symmetric)\n",
    "                peaks_1 = np.array(peak_indices[cfu_1])\n",
    "                peaks_2 = np.array(peak_indices[cfu_2])\n",
    "                for peak_1 in peaks_1:\n",
    "                    matches = np.any(np.abs(peaks_2 - peak_1) <= tolerance_frames)\n",
    "                    overlap_matrix[i, j] += matches\n",
    "    overlap_matrix = overlap_matrix + overlap_matrix.T - np.diag(overlap_matrix.diagonal())\n",
    "    overlap_df = pd.DataFrame(overlap_matrix, index=cfus, columns=cfus)\n",
    "    fig = px.imshow(\n",
    "        overlap_df,\n",
    "        labels=dict(x=\"CFU\", y=\"CFU\", color=\"Peak Overlap Count\"),\n",
    "        x=cfus,\n",
    "        y=cfus,\n",
    "        color_continuous_scale=\"Viridis\",\n",
    "        title=f\"Peak Overlap Heatmap (Tolerance: +/- {tolerance_frames} frames)\"\n",
    "    )\n",
    "    time_tolerance = tolerance_frames / fps\n",
    "    fig.add_annotation(\n",
    "        text=f\"Time Tolerance: +/- {time_tolerance:.2f} seconds\",\n",
    "        xref=\"paper\", yref=\"paper\",\n",
    "        x=1.1, y=1.1, showarrow=False\n",
    "    )\n",
    "    heatmap_path = f\"{output_path}\\peak_overlap_heatmap.html\"\n",
    "    fig.write_html(heatmap_path)\n",
    "    print(f\"Saved heatmap to {heatmap_path}\")\n",
    "\n",
    "    return overlap_df\n",
    "\n",
    "def plot_high_overlap_pairs(df, smoothed_data_dict, peak_indices, overlap_df, overlap_threshold, fps, output_dir):\n",
    "    \"\"\"\n",
    "    Identifies CFU pairs with more than a specified overlap threshold and plots their data together,\n",
    "    highlighting regions with overlapped peaks.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original CFU data.\n",
    "        smoothed_data_dict (dict): Dictionary of smoothed data for each CFU.\n",
    "        peak_indices (dict): Dictionary of detected peaks for each CFU.\n",
    "        overlap_df (pd.DataFrame): Overlap percentage DataFrame.\n",
    "        overlap_threshold (float): Threshold for overlap percentage to consider pairs.\n",
    "        fps (float): Frames per second of the data.\n",
    "        output_dir (str): Directory to save the plots.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    high_overlap_pairs = [\n",
    "        (cfu_1, cfu_2) for cfu_1 in overlap_df.index for cfu_2 in overlap_df.columns\n",
    "        if cfu_1 != cfu_2 and overlap_df.loc[cfu_1, cfu_2] > overlap_threshold\n",
    "    ]\n",
    "\n",
    "    for cfu_1, cfu_2 in high_overlap_pairs:\n",
    "        original_data_1 = df[cfu_1].values\n",
    "        smoothed_data_1 = smoothed_data_dict[cfu_1]\n",
    "        peaks_1 = np.array(peak_indices[cfu_1])\n",
    "\n",
    "        original_data_2 = df[cfu_2].values\n",
    "        smoothed_data_2 = smoothed_data_dict[cfu_2]\n",
    "        peaks_2 = np.array(peak_indices[cfu_2])\n",
    "\n",
    "        time_seconds = np.arange(len(original_data_1)) / fps  # Convert frame numbers to seconds\n",
    "        overlapping_peaks = [\n",
    "            peak_1 for peak_1 in peaks_1 if np.any(np.abs(peaks_2 - peak_1) <= 4)\n",
    "        ]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=time_seconds, y=original_data_1, mode='lines',\n",
    "            name=f\"Original {cfu_1}\", line=dict(color=\"blue\", width=1)\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=time_seconds, y=smoothed_data_1, mode='lines',\n",
    "            name=f\"Smoothed {cfu_1}\", line=dict(color=\"green\", width=2)\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=time_seconds[peaks_1], y=smoothed_data_1[peaks_1], mode='markers',\n",
    "            name=f\"Peaks {cfu_1}\", marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=time_seconds, y=original_data_2, mode='lines',\n",
    "            name=f\"Original {cfu_2}\", line=dict(color=\"purple\", width=1)\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=time_seconds, y=smoothed_data_2, mode='lines',\n",
    "            name=f\"Smoothed {cfu_2}\", line=dict(color=\"orange\", width=2)\n",
    "        ))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=time_seconds[peaks_2], y=smoothed_data_2[peaks_2], mode='markers',\n",
    "            name=f\"Peaks {cfu_2}\", marker=dict(color='black', size=8)\n",
    "        ))\n",
    "        for overlap_peak in overlapping_peaks:\n",
    "            overlap_time = time_seconds[overlap_peak]\n",
    "            fig.add_vrect(\n",
    "                x0=overlap_time - (4 / fps), x1=overlap_time + (4 / fps),\n",
    "                fillcolor=\"rgba(255, 0, 0, 0.3)\", layer=\"below\", line_width=0\n",
    "            )\n",
    "        fig.update_layout(\n",
    "            title=f\"High Overlap Between {cfu_1} and {cfu_2} (> {overlap_threshold}%)\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        output_path = os.path.join(output_dir, f\"overlap_{cfu_1}_{cfu_2}.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved high-overlap plot for {cfu_1} and {cfu_2} to {output_path}\")\n",
    "def bin_dataframe(df, bin_factor=2):\n",
    "    \"\"\"\n",
    "    Bins a dataframe by averaging consecutive rows in groups of bin_factor.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input dataframe where rows represent frames and columns represent measurements (e.g., CFUs).\n",
    "        bin_factor (int): Number of consecutive rows to average.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Binned dataframe with reduced row count.\n",
    "    \"\"\"\n",
    "    num_rows = df.shape[0]\n",
    "    if num_rows % bin_factor != 0:\n",
    "        print(f\"Warning: Number of rows ({num_rows}) is not divisible by bin_factor ({bin_factor}). \"\n",
    "              f\"Truncating to {num_rows - (num_rows % bin_factor)} rows.\")\n",
    "        df = df.iloc[:num_rows - (num_rows % bin_factor)]\n",
    "    binned_data = (\n",
    "        df.values.reshape(-1, bin_factor, df.shape[1])\n",
    "        .mean(axis=1)\n",
    "    )\n",
    "    binned_df = pd.DataFrame(binned_data, columns=df.columns)\n",
    "\n",
    "    return binned_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcd282-ea16-4a56-880c-30be934dc70f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362713a1-6836-469b-b6e4-29bdf177535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_folder = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\All_CFUs.mat'\n",
    "link_save = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\Save'\n",
    "link_file = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop4_1.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc46dd2-9777-457c-b4f4-f5d2921e185d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53121c-0522-46b3-8418-2d9eed4bd3ce",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54886d0-1399-4fb7-a8c5-f6174c67a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(link_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04bbdea-beb5-49e2-8bf9-606e2d350ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_base = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\CFU_'\n",
    "links_list = []\n",
    "cfu_base = r'cfuInfo1'\n",
    "cfu_list = []\n",
    "path_to_s = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\path_'\n",
    "for i in range(9):\n",
    "    links_list.append(link_base + str(i+1))\n",
    "    cfu_list.append(cfu_base + str(i+1))\n",
    "print('CFU list: ' + str(cfu_list))\n",
    "print('links list: ' + str(links_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842d5bd-bfe5-4d40-8cf6-3d9e01aa0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    cfu_to_tif(links_list[i], cfu_list[i], path_to_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f7d6b-ea7f-4b70-a062-33da93155e4f",
   "metadata": {},
   "source": [
    "Save all plotted intensities from the All_CFUs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689fa79-418d-499e-8465-3994c89becbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cfus = scipy.io.loadmat(link_folder)['All_CFUs']\n",
    "output_dir = link_save + '\\All_CFUs_'  # Set your desired output directory\n",
    "\n",
    "for i, row in enumerate(all_cfus):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=row, mode='lines', name=f\"Row {i + 1}\"))\n",
    "    fig.update_layout(\n",
    "        title=f\"Graph for Row {i + 1}\",\n",
    "        xaxis_title=\"Index\",\n",
    "        yaxis_title=\"Intensity\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    output_path = output_dir + f\"row_{i + 1}_graph.html\"\n",
    "    fig.write_html(output_path)\n",
    "    print(f\"Saved interactive graph for row {i + 1} as {output_path}\")\n",
    "\n",
    "fig_combined = go.Figure()\n",
    "for i, row in enumerate(all_cfus):\n",
    "    fig_combined.add_trace(go.Scatter(y=row, mode='lines', name=f\"Row {i + 1}\"))\n",
    "fig_combined.update_layout(\n",
    "    title=\"All Rows Combined\",\n",
    "    xaxis_title=\"Index\",\n",
    "    yaxis_title=\"Intensity\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Save the combined graph\n",
    "combined_output_path = output_dir + \"all_rows_combined_graph.html\"\n",
    "fig_combined.write_html(combined_output_path)\n",
    "print(f\"Saved combined interactive graph as {combined_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086367b-0ad6-469e-99d3-1856aabe8e96",
   "metadata": {},
   "source": [
    "make the CFUs data from matlab as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316dc39-0afc-4f00-82f1-a0a7b4ef70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus = pd.DataFrame(scipy.io.loadmat(r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\All_CFUs.mat')['All_CFUs'])\n",
    "df_all_cfus_df = pd.DataFrame(scipy.io.loadmat(r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\All_CFUs_df.mat')['All_cfu_df'])\n",
    "df_all_cfus = df_trans_ren(df_all_cfus, 'CFU_')\n",
    "df_all_cfus_df = df_trans_ren(df_all_cfus_df, 'CFU_DF_')\n",
    "df_all_cfus_bg_corr = df_all_cfus-110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c3068-36da-44c5-b118-a59316131e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus_baseline = calculate_baseline(df_all_cfus, sigma=10, deg=5)\n",
    "df_all_cfus_df_baseline = calculate_baseline(df_all_cfus_df, sigma=10, deg=5)\n",
    "df_all_cfus_bg_corr_baseline = calculate_baseline(df_all_cfus_bg_corr, sigma=10, deg=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f792e9f-1479-43d0-8011-2c4b9e5c542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus_bg_corr_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be24e64-cc4c-4fb2-8b20-a19cf6f68d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus_bg_corr_df =pd.DataFrame()\n",
    "for col in df_all_cfus_bg_corr.columns:\n",
    "    df_all_cfus_bg_corr_df[col] = (df_all_cfus_bg_corr[col]-df_all_cfus_bg_corr_baseline[col])/df_all_cfus_bg_corr_baseline[col]\n",
    "\n",
    "df_all_cfus_bg_corr_df_baseline = calculate_baseline(df_all_cfus_bg_corr_df, sigma=10, deg=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a5c47-9bf6-45b8-9f29-b7449e147f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus_bg_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbff63c-4466-411f-a279-a72921afe0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save(df_all_cfus_bg_corr, df_all_cfus_bg_corr_baseline, link_save + '\\corrected_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbfe621-91d6-45f7-9427-ec22379dbc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save(df_all_cfus_bg_corr_df, df_all_cfus_bg_corr_df_baseline, link_save + '\\corrected_df_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4cf62-799a-4caa-9fd5-25245ce938f8",
   "metadata": {},
   "source": [
    "data from tif file through masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a11786-58de-4a5c-b02a-a4502ce55bbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Peak detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d65ac9-2e94-49fe-aff9-ac3f6080c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices_df_aqua, peak_counts_df_aqua = detect_peaks(\n",
    "    df=df_all_cfus_df,\n",
    "    height=0.1,        # Minimum height of peaks (adjust as needed)\n",
    "    prominence=0.08,   # Minimum prominence of peaks\n",
    "    distance=30        # Minimum distance between peaks\n",
    ")\n",
    "\n",
    "print(peak_counts_df_aqua)\n",
    "plot_peaks(df_all_cfus_df, peak_indices_df_aqua, link_save + '\\CFU_Peaks_fromaqua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecddb0a-e009-4f12-b26e-23460f9a2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices, peak_counts_df = detect_peaks(\n",
    "    df=df_all_cfus_bg_corr_df,\n",
    "    height=0.1,        # Minimum height of peaks (adjust as needed)\n",
    "    prominence=0.08,   # Minimum prominence of peaks\n",
    "    distance=30        # Minimum distance between peaks\n",
    ")\n",
    "\n",
    "print(peak_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4a442-9416-4439-8ca5-c274fec3940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peaks(df_all_cfus_bg_corr_df, peak_indices, link_save + '\\CFU_Peaks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbabcdc7-550c-4945-92ea-692303c5fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\CFU_Smoothed_Peaks\"\n",
    "peak_indices, smoothed_data_dict, peak_counts_df = detect_peaks_on_smoothed_data(\n",
    "    df=df_all_cfus_bg_corr_df,  # Replace with your DataFrame\n",
    "    sigma=2,\n",
    "    height=0.1,\n",
    "    prominence=0.08,\n",
    "    distance=30\n",
    ")\n",
    "plot_peaks_on_smoothed_data(df_all_cfus_bg_corr_df, smoothed_data_dict, peak_indices, output_dir)\n",
    "peak_counts_df.to_csv(os.path.join(output_dir, \"peak_counts.csv\"))\n",
    "np.save(os.path.join(output_dir, \"peak_indices.npy\"), peak_indices)\n",
    "print(f\"Peak counts saved to {os.path.join(output_dir, 'peak_counts.csv')}\")\n",
    "print(f\"Peak indices saved to {os.path.join(output_dir, 'peak_indices.npy')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe5aff-335e-4ada-8772-ac43164aa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_file = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop4_1.tif\"\n",
    "mask_folder = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\Masks\"\n",
    "output_csv = link_save + \"\\intensity_data.csv\"\n",
    "output_dir = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\Save\\from_tif_dff\"\n",
    "\n",
    "cropped_tiff_file = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop4_1_cropped_file.tiff\"\n",
    "with tiff.TiffFile(tiff_file) as tif:\n",
    "    tiff_data = tif.asarray()\n",
    "print(f\"Original TIFF shape: {tiff_data.shape}\")\n",
    "tiff_data_cropped = crop_tiff_dimensions(tiff_data, crop_pixels=5)\n",
    "print(f\"Cropped TIFF shape: {tiff_data_cropped.shape}\")\n",
    "\n",
    "tiff.imwrite(cropped_tiff_file, tiff_data_cropped)\n",
    "print(f\"Cropped TIFF saved to {cropped_tiff_file}\")\n",
    "\n",
    "intensity_data = calculate_intensities(cropped_tiff_file, mask_folder, output_csv)\n",
    "intensity_data_corr = pd.DataFrame()\n",
    "for col in intensity_data.columns:\n",
    "    intensity_data_corr[col] = intensity_data[col] - intensity_data[col].min() +50\n",
    "dff_data = calculate_dff(intensity_data_corr)\n",
    "peak_indices, peak_counts_df = detect_peaks(dff_data, height=0.1, prominence=0.05, distance=20)\n",
    "plot_dff_and_peaks(dff_data, peak_indices, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f32e53-7b1c-401d-b3b9-8a11e0782cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices, peak_counts_df = detect_peaks(\n",
    "    df=dff_data,\n",
    "    height=0.1,        # Minimum height of peaks (adjust as needed)\n",
    "    prominence=0.1,   # Minimum prominence of peaks\n",
    "    distance=50        # Minimum distance between peaks\n",
    ")\n",
    "\n",
    "print(peak_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584674b8-c55c-482c-844d-c90adbffcb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 30.0  # Example: 30 frames per second\n",
    "all_peaks = []\n",
    "for roi, indices in peak_indices.items():\n",
    "    all_peaks.extend(indices)\n",
    "peak_times = np.array(all_peaks) / frame_rate\n",
    "time_bins = np.arange(0, peak_times.max() + 1, 1)  # From 0 to max peak time, in 1-second bins\n",
    "peak_counts, bin_edges = np.histogram(peak_times, bins=time_bins)\n",
    "density_df = pd.DataFrame({\n",
    "    \"Time (s)\": bin_edges[:-1],  # Start of each bin\n",
    "    \"Peak Density\": peak_counts\n",
    "})\n",
    "plt.bar(density_df[\"Time (s)\"], density_df[\"Peak Density\"], width=1, align='edge', color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Peak Density (Peaks per Second)\")\n",
    "plt.title(\"Density of Detected Peaks per Second\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8b8a1-ab9d-47a1-bb05-b59a55611ceb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Get masks from mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf80d1-4654-4f90-b377-e68a514a2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_folder = r'E:\\Data\\241105_CM006\\unit4'\n",
    "link_file_mat = r'E:\\Data\\241105_CM006\\unit4\\unit4_32_crop_2_AQuA2.mat'\n",
    "mat = scipy.io.loadmat(link_folder_cm006_unit4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc379387-3aa8-43b5-9613-05007bf899c8",
   "metadata": {},
   "source": [
    "mat['cfuInfo1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50471fc-2143-4afb-828d-d3a19dd1cd08",
   "metadata": {},
   "source": [
    "mat.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e7395-f418-4394-9fb1-e7654fcf25af",
   "metadata": {},
   "source": [
    "list(mat.keys())[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b844d33-21f1-4e95-a158-ff8991bd9446",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_test = {}\n",
    "mask_name = 'Mask_'\n",
    "for i in range(13):\n",
    "    df_test[i] = Image.fromarray((mat['cfuInfo1'][i][2] / np.max( mat['cfuInfo1'][i][2]) * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82444e5-534a-4887-a14d-4b1f984a7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(link_file_mat)\n",
    "cfu_to_tif_global(link_file_mat, link_save, list(mat.keys())[3], 2)\n",
    "pd_data, pd_data_df = get_data_global(link_file_mat, link_folder + '\\Save', list(mat.keys())[3])\n",
    "pd_data_df = pd.DataFrame(pd_data_df)\n",
    "pd_data = pd.DataFrame(pd_data)\n",
    "pd_data_corr = pd_data-110\n",
    "pd_data_corr_baseline = calculate_baseline(pd_data_corr, sigma=10, deg=5)\n",
    "pd_data_corr_df =pd.DataFrame()\n",
    "for col in pd_data_corr_baseline .columns:\n",
    "    pd_data_corr_df[col] = (pd_data_corr[col]-pd_data_corr_baseline[col])/pd_data_corr_baseline[col]\n",
    "\n",
    "pd_data_corr_df_baselinetocheck = calculate_baseline(pd_data_corr_df, sigma=10, deg=5)\n",
    "plot_and_save(pd_data_corr_df, pd_data_corr_df_baselinetocheck, link_folder + '\\Save' + '\\corrected_baseline')\n",
    "peak_indices_df, peak_counts_df = detect_peaks(\n",
    "    df=pd_data_corr_df,\n",
    "    height=0.1,        # Minimum height of peaks (adjust as needed)\n",
    "    prominence=0.08,   # Minimum prominence of peaks\n",
    "    distance=30        # Minimum distance between peaks\n",
    ")\n",
    "\n",
    "print(peak_counts_df)\n",
    "plot_peaks(pd_data_corr_df, peak_indices_df, link_folder + '\\Save' + '\\CFU_Peaks_calc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acacd8-9ffe-4519-90b4-9fff12b02d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd_data_corr_df\n",
    "peak_indices, smoothed_data, peak_counts = detect_peaks_on_smoothed_data(df, fs=30.9, cutoff=5, height=0.1, prominence=0.2, distance=15)\n",
    "print(peak_counts)\n",
    "time = np.linspace(0, len(df[cfu]) / 30.9, len(df[cfu]))\n",
    "cfu = \"Mask_1\"\n",
    "original_data = df[cfu].values\n",
    "smoothed = smoothed_data[cfu]\n",
    "peaks = peak_indices[cfu]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=original_data, mode='lines', name=\"Original Data\", line=dict(color=\"blue\", width=1)))\n",
    "fig.add_trace(go.Scatter(x=time, y=smoothed, mode='lines', name=\"Smoothed Data\", line=dict(color=\"green\", width=2)))\n",
    "fig.add_trace(go.Scatter(x=time[peaks], y=smoothed[peaks], mode='markers', name=\"Peaks\", marker=dict(color='red', size=8)))\n",
    "fig.update_layout(\n",
    "    title=f\"Peaks for {cfu}\",\n",
    "    xaxis_title=\"Time (s)\",\n",
    "    yaxis_title=\"Intensity\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=1, y=1)\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e867b-607f-4913-96b3-5a40bfad9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfu = \"Mask_1\"\n",
    "original_data = df[cfu].values\n",
    "smoothed = smoothed_data[cfu]\n",
    "peaks = peak_indices[cfu]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=original_data, mode='lines', name=\"Original Data\", line=dict(color=\"blue\", width=1)))\n",
    "fig.add_trace(go.Scatter(x=time, y=smoothed, mode='lines', name=\"Smoothed Data\", line=dict(color=\"green\", width=2)))\n",
    "fig.add_trace(go.Scatter(x=time[peaks], y=smoothed[peaks], mode='markers', name=\"Peaks\", marker=dict(color='red', size=8)))\n",
    "fig.update_layout(\n",
    "    title=f\"Peaks for {cfu}\",\n",
    "    xaxis_title=\"Time (s)\",\n",
    "    yaxis_title=\"Intensity\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=1, y=1)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8dd48c-ed43-414b-80a2-d63250e5380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop2_32\\Save' + '\\CFU_Peaks_calc_smooth'\n",
    "plot_peaks_on_smoothed_data_with_baseline(df, smoothed_data, peak_indices, pd_data_corr_df_baselinetocheck, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc742f55-5230-4cbb-b98e-e76b302d5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_peak_density_per_cfu(peak_indices, fs=30.9, output_dir=r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop2_32\\Save' + '\\CFU_Peaks_dencity' ,bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e35d7e-fec3-49d3-baf5-36dd2fa1f05f",
   "metadata": {},
   "source": [
    "# Script to run for the data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ac6b9-6aa3-479d-a3a4-fc5c7392e181",
   "metadata": {},
   "source": [
    "How to use?\n",
    "\n",
    "- get the tiff files from anywhere, better - suite2p corrected\n",
    "- convert to 32 bit through ImageJ, crop to get the final size less than 4 Gb\n",
    "- save the final file\n",
    "- recommended to create a folder to place the file\n",
    "- run the AQuA2 in Matlab (no excluded borders, set the fps etc.), threshold on 2-3, test a few)\n",
    "- run CFU and choose the CFUs that you need\n",
    "- load the traces to the workspace and save the .mat file with the masks and traces to the previously created folder\n",
    "\n",
    "Then:\n",
    "- set up the standard conda env and install all necessary libs\n",
    "- run the imports\n",
    "- run the functions\n",
    "- create the cell with the links to the .mat file and where to save the outputs\n",
    "- run the cell with links and the script cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9201a4-805a-43a6-9e0c-e56c887350b5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Links (current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ef1a0-ed55-4124-afe5-3e53ce1a28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM006 Unit4 crop 2\n",
    "link_folder = r'E:\\Data\\241105_CM006\\unit4'\n",
    "link_file_mat = r'E:\\Data\\241105_CM006\\unit4\\unit4_32_crop_2_AQuA2.mat'\n",
    "link_save = r'E:\\Data\\241105_CM006\\unit4\\Save'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd8ea3-55f2-483a-af48-2edbb666f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM005 Unit10 \n",
    "link_folder = r'E:\\CM005_unit10'\n",
    "link_file_mat = r'E:\\CM005_unit10\\cm005_unit10.mat'\n",
    "link_save = r'E:\\CM005_unit10\\Save'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 54\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d94a9-79c6-4db1-8e69-92d28d662d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM006 Unit8 \n",
    "link_folder = r'E:\\Data\\241105_CM006\\unit8'\n",
    "link_file_mat = r'E:\\Data\\241105_CM006\\unit8\\unit8_32_bottomhalf.mat'\n",
    "link_save = r'E:\\Data\\241105_CM006\\unit8\\Save'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.3        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452e7c3e-458c-45c0-be3d-a8a3e1fc8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM005 Unit5 \n",
    "link_folder = r'E:\\Data\\241106_CM005\\unit5'\n",
    "link_file_mat = r'E:\\Data\\241106_CM005\\unit5\\unit5_32_corr.mat'\n",
    "link_save = r'E:\\Data\\241106_CM005\\unit5\\Save'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49dd075-c09b-49b3-94a3-2c06ea720e1c",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee676315-8e04-4e56-95c7-75730fa55cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 241202_CM005_rec1_more_unit0_32_crop\n",
    "link_folder = r'E:\\Data\\analysis_cm005'\n",
    "link_file_mat = r'E:\\Data\\analysis_cm005\\241202_CM005_rec1_more_unit0_32_crop.mat'\n",
    "link_save = r'E:\\Data\\analysis_cm005\\Save_241202_CM005_rec1_more_unit0_32_crop'\n",
    "sigma_value = 7\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5\n",
    "\n",
    "cols_list = ['Mask_0','Mask_50', 'Mask_61', 'Mask_43']\n",
    "cfu_list = ['CFU_0','CFU_50', 'CFU_61', 'CFU_43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5c25b946-6302-4531-8ec0-070d7a1ea314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 241202_CM005_rec1_unit4_32_all\n",
    "link_folder = r'E:\\Data\\analysis_cm005'\n",
    "link_file_mat = r'E:\\Data\\analysis_cm005\\241202_CM005_rec1_unit4_32_all.mat'\n",
    "link_save = r'E:\\Data\\analysis_cm005\\Save_241202_CM005_rec1_unit4_32_all'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 61\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5\n",
    "\n",
    "cols_list = ['Mask_0','Mask_95', 'Mask_99', 'Mask_110','Mask_115', 'Mask_117', 'Mask_174']\n",
    "#cfu_list = ['CFU_0','CFU_50', 'CFU_61', 'CFU_43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "365dc9fa-660a-46f9-a831-8eec0dabbc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 241202_CM005_rec2_unit5_32_crop_AQuA2\n",
    "link_folder = r'E:\\Data\\analysis_cm005'\n",
    "link_file_mat = r'E:\\Data\\analysis_cm005\\241202_CM005_rec2_unit5_32_crop_AQuA2.mat'\n",
    "link_save = r'E:\\Data\\analysis_cm005\\Save_241202_CM005_rec2_unit5_32_crop_AQuA2'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 61.8\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5\n",
    "\n",
    "cols_list = ['Mask_0','Mask_10','Mask_11', 'Mask_12', 'Mask_28','Mask_31']\n",
    "#cfu_list = ['CFU_0','CFU_50', 'CFU_61', 'CFU_43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "947c3cdc-6291-43ef-96ef-bc1a0ed9df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 241106_CM005_unit5_32_corr_upd\n",
    "link_folder = r'E:\\Data\\analysis_cm005'\n",
    "link_file_mat = r'E:\\Data\\analysis_cm005\\241106_CM005_unit5_32_corr_upd.mat'\n",
    "link_save = r'E:\\Data\\analysis_cm005\\Save_241106_CM005_unit5_32_corr_upd'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.15        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5\n",
    "\n",
    "cols_list = ['Mask_0','Mask_3', 'Mask_4', 'Mask_7','Mask_6','Mask_14', 'Mask_15', 'Mask_16','Mask_17', 'Mask_18','Mask_20']\n",
    "#cfu_list = ['CFU_0','CFU_50', 'CFU_61', 'CFU_43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d190d5ca-adde-4cb0-b5af-e1305950300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 241106_CM005_unit10_32_upd\n",
    "link_folder = r'E:\\Data\\analysis_cm005'\n",
    "link_file_mat = r'E:\\Data\\analysis_cm005\\241106_CM005_unit10_32_upd.mat'\n",
    "link_save = r'E:\\Data\\analysis_cm005\\Save_241106_CM005_unit10_32_upd'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 52\n",
    "height_value=0.3        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5\n",
    "\n",
    "cols_list = ['Mask_0','Mask_48', 'Mask_51', 'Mask_54','Mask_62']\n",
    "#cfu_list = ['CFU_0','CFU_50', 'CFU_61', 'CFU_43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "40d3dd24-b3d6-4f57-8666-85cf044c461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 241106_CM005_unit9_32_upd\n",
    "link_folder = r'E:\\Data\\analysis_cm005'\n",
    "link_file_mat = r'E:\\Data\\analysis_cm005\\241106_CM005_unit9_32_upd.mat'\n",
    "link_save = r'E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 52\n",
    "height_value=0.3        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5\n",
    "\n",
    "cols_list = ['Mask_0','Mask_48', 'Mask_51', 'Mask_54','Mask_62']\n",
    "#cfu_list = ['CFU_0','CFU_50', 'CFU_61', 'CFU_43']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d457dc6b-2b1c-446f-9058-7a8f26fecba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(link_file_mat)\n",
    "cfu_to_tif_global(link_file_mat, link_save, list(mat.keys())[3], 2)\n",
    "pd_data, pd_data_df = get_data_global(link_file_mat, link_save, list(mat.keys())[3])\n",
    "pd_data_df = pd.DataFrame(pd_data_df)\n",
    "pd_data = pd.DataFrame(pd_data)\n",
    "pd_data_corr = pd_data-110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "69c69104-268e-4ca5-bd25-40ee188be002",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data_corr = bin_dataframe(pd_data_corr, bin_factor=2)\n",
    "fs_value = fs_value/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cc2c50d2-496d-4c07-8b3c-77691acaba41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd_data_corr_baseline = calculate_baseline(pd_data_corr, sigma=sigma_value, deg = deg_value)\n",
    "pd_data_corr_df = pd.DataFrame()\n",
    "for col in pd_data_corr_baseline .columns:\n",
    "    pd_data_corr_df[col] = (pd_data_corr[col]-pd_data_corr_baseline[col])/pd_data_corr_baseline[col]\n",
    "pd_data_corr_df_baselinetocheck = calculate_baseline(pd_data_corr_df, sigma=sigma_value, deg = deg_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6f4485c9-2cd5-4306-a83f-bdf24ce73656",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Mask_48', 'Mask_51', 'Mask_54', 'Mask_62'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[121], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pd_data_df \u001b[38;5;241m=\u001b[39m pd_data_df[cols_list]\n\u001b[0;32m      2\u001b[0m pd_data_corr \u001b[38;5;241m=\u001b[39m pd_data_corr[cols_list]\n\u001b[0;32m      3\u001b[0m pd_data_corr_df \u001b[38;5;241m=\u001b[39m pd_data_corr_df[cols_list]\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fordata\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fordata\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\fordata\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Mask_48', 'Mask_51', 'Mask_54', 'Mask_62'] not in index\""
     ]
    }
   ],
   "source": [
    "pd_data_df = pd_data_df[cols_list]\n",
    "pd_data_corr = pd_data_corr[cols_list]\n",
    "pd_data_corr_df = pd_data_corr_df[cols_list]\n",
    "pd_data_corr_df_baselinetocheck = pd_data_corr_df_baselinetocheck[cols_list]\n",
    "pd_data_corr_baseline = pd_data_corr_baseline[cols_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "44fdd30b-5e56-4db1-8770-5e64f2ea8b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved interactive graph for CFU Mask_0 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_0_graph.html\n",
      "Saved interactive graph for CFU Mask_1 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_1_graph.html\n",
      "Saved interactive graph for CFU Mask_2 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_2_graph.html\n",
      "Saved interactive graph for CFU Mask_3 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_3_graph.html\n",
      "Saved interactive graph for CFU Mask_4 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_4_graph.html\n",
      "Saved interactive graph for CFU Mask_5 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_5_graph.html\n",
      "Saved interactive graph for CFU Mask_6 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_6_graph.html\n",
      "Saved interactive graph for CFU Mask_7 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_7_graph.html\n",
      "Saved interactive graph for CFU Mask_8 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_8_graph.html\n",
      "Saved interactive graph for CFU Mask_9 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_9_graph.html\n",
      "Saved interactive graph for CFU Mask_10 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_10_graph.html\n",
      "Saved interactive graph for CFU Mask_11 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_11_graph.html\n",
      "Saved interactive graph for CFU Mask_12 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_12_graph.html\n",
      "Saved interactive graph for CFU Mask_13 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_13_graph.html\n",
      "Saved interactive graph for CFU Mask_14 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_14_graph.html\n",
      "Saved interactive graph for CFU Mask_15 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_15_graph.html\n",
      "Saved interactive graph for CFU Mask_16 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_16_graph.html\n",
      "Saved interactive graph for CFU Mask_17 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_17_graph.html\n",
      "Saved interactive graph for CFU Mask_18 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_18_graph.html\n",
      "Saved interactive graph for CFU Mask_19 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_19_graph.html\n",
      "Saved interactive graph for CFU Mask_20 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_20_graph.html\n",
      "Saved interactive graph for CFU Mask_21 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_21_graph.html\n",
      "Saved interactive graph for CFU Mask_22 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_22_graph.html\n",
      "Saved interactive graph for CFU Mask_23 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_23_graph.html\n",
      "Saved interactive graph for CFU Mask_24 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_24_graph.html\n",
      "Saved interactive graph for CFU Mask_25 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_25_graph.html\n",
      "Saved interactive graph for CFU Mask_26 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_26_graph.html\n",
      "Saved interactive graph for CFU Mask_27 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_27_graph.html\n",
      "Saved interactive graph for CFU Mask_28 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_28_graph.html\n",
      "Saved interactive graph for CFU Mask_29 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_29_graph.html\n",
      "Saved interactive graph for CFU Mask_30 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_30_graph.html\n",
      "Saved interactive graph for CFU Mask_31 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_31_graph.html\n",
      "Saved interactive graph for CFU Mask_32 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_32_graph.html\n",
      "Saved interactive graph for CFU Mask_33 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_33_graph.html\n",
      "Saved interactive graph for CFU Mask_34 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_34_graph.html\n",
      "Saved interactive graph for CFU Mask_35 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_35_graph.html\n",
      "Saved interactive graph for CFU Mask_36 as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\cfu_Mask_36_graph.html\n",
      "Saved combined graph as E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\corrected_baseline\\all_cfus_combined_graph.html\n",
      "         Peak Count\n",
      "CFU                \n",
      "Mask_0          158\n",
      "Mask_1           78\n",
      "Mask_2           38\n",
      "Mask_3           33\n",
      "Mask_4           17\n",
      "Mask_5           17\n",
      "Mask_6           36\n",
      "Mask_7           18\n",
      "Mask_8           17\n",
      "Mask_9           19\n",
      "Mask_10          19\n",
      "Mask_11          59\n",
      "Mask_12          27\n",
      "Mask_13          19\n",
      "Mask_14          69\n",
      "Mask_15          15\n",
      "Mask_16           7\n",
      "Mask_17          70\n",
      "Mask_18          17\n",
      "Mask_19          28\n",
      "Mask_20          80\n",
      "Mask_21          13\n",
      "Mask_22          42\n",
      "Mask_23          21\n",
      "Mask_24          20\n",
      "Mask_25          61\n",
      "Mask_26          17\n",
      "Mask_27         201\n",
      "Mask_28          18\n",
      "Mask_29          18\n",
      "Mask_30          18\n",
      "Mask_31          29\n",
      "Mask_32          38\n",
      "Mask_33          54\n",
      "Mask_34          17\n",
      "Mask_35          22\n",
      "Mask_36          39\n",
      "Saved peak detection graph for CFU Mask_0 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_0_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_1 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_1_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_2 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_2_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_3 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_3_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_4 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_4_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_5 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_5_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_6 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_6_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_7 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_7_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_8 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_8_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_9 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_9_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_10 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_10_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_11 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_11_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_12 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_12_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_13 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_13_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_14 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_14_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_15 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_15_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_16 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_16_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_17 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_17_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_18 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_18_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_19 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_19_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_20 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_20_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_21 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_21_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_22 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_22_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_23 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_23_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_24 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_24_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_25 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_25_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_26 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_26_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_27 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_27_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_28 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_28_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_29 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_29_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_30 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_30_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_31 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_31_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_32 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_32_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_33 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_33_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_34 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_34_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_35 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_35_smoothed_peaks.html\n",
      "Saved peak detection graph for CFU Mask_36 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\cfu_Mask_36_smoothed_peaks.html\n",
      "Saved combined peak detection graph to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_calc_smooth\\all_cfus_smoothed_peaks_combined.html\n",
      "Saved peak density plot for Mask_0 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_0.html\n",
      "Saved peak density plot for Mask_1 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_1.html\n",
      "Saved peak density plot for Mask_2 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_2.html\n",
      "Saved peak density plot for Mask_3 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_3.html\n",
      "Saved peak density plot for Mask_4 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_4.html\n",
      "Saved peak density plot for Mask_5 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_5.html\n",
      "Saved peak density plot for Mask_6 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_6.html\n",
      "Saved peak density plot for Mask_7 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_7.html\n",
      "Saved peak density plot for Mask_8 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_8.html\n",
      "Saved peak density plot for Mask_9 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_9.html\n",
      "Saved peak density plot for Mask_10 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_10.html\n",
      "Saved peak density plot for Mask_11 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_11.html\n",
      "Saved peak density plot for Mask_12 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_12.html\n",
      "Saved peak density plot for Mask_13 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_13.html\n",
      "Saved peak density plot for Mask_14 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_14.html\n",
      "Saved peak density plot for Mask_15 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_15.html\n",
      "Saved peak density plot for Mask_16 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_16.html\n",
      "Saved peak density plot for Mask_17 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_17.html\n",
      "Saved peak density plot for Mask_18 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_18.html\n",
      "Saved peak density plot for Mask_19 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_19.html\n",
      "Saved peak density plot for Mask_20 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_20.html\n",
      "Saved peak density plot for Mask_21 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_21.html\n",
      "Saved peak density plot for Mask_22 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_22.html\n",
      "Saved peak density plot for Mask_23 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_23.html\n",
      "Saved peak density plot for Mask_24 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_24.html\n",
      "Saved peak density plot for Mask_25 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_25.html\n",
      "Saved peak density plot for Mask_26 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_26.html\n",
      "Saved peak density plot for Mask_27 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_27.html\n",
      "Saved peak density plot for Mask_28 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_28.html\n",
      "Saved peak density plot for Mask_29 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_29.html\n",
      "Saved peak density plot for Mask_30 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_30.html\n",
      "Saved peak density plot for Mask_31 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_31.html\n",
      "Saved peak density plot for Mask_32 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_32.html\n",
      "Saved peak density plot for Mask_33 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_33.html\n",
      "Saved peak density plot for Mask_34 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_34.html\n",
      "Saved peak density plot for Mask_35 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_35.html\n",
      "Saved peak density plot for Mask_36 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\CFU_Peaks_dencity\\peak_density_Mask_36.html\n",
      "Saved CFU analysis to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\cfu_analysis.csv\n",
      "Saved detected peaks summary to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\detected_peaks_summary.csv\n",
      "Saved analysis report to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\analysis_report.txt\n",
      "Saved combined plot for Mask_0 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_1 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_2 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_3 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_4 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_5 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_6 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_7 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_8 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_9 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_10 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_11 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_12 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_13 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_14 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_15 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_16 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_17 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_18 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_19 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_20 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_21 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_22 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_23 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_24 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_25 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_26 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_27 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_28 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_29 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_30 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_31 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_32 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_33 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_34 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_35 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved combined plot for Mask_36 to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\n",
      "Saved heatmap to E:\\Data\\analysis_cm005\\Save_241106_CM005_unit9_32_upd\\peak_overlap_heatmap.html\n"
     ]
    }
   ],
   "source": [
    "plot_and_save(pd_data_corr_df, pd_data_corr_df_baselinetocheck, link_save + '\\corrected_baseline')\n",
    "output_dir = link_save + '\\CFU_Peaks_calc_smooth'\n",
    "peak_indices, smoothed_data, peak_counts = detect_peaks_on_smoothed_data(pd_data_corr_df, \n",
    "                                                                         fs=fs_value, \n",
    "                                                                         cutoff=cutoff_value, \n",
    "                                                                         height=height_value,        # Minimum height of peaks (adjust as needed)\n",
    "                                                                         prominence=prominence_value,   # Minimum prominence of peaks\n",
    "                                                                         distance=distance_value )\n",
    "print(peak_counts)\n",
    "plot_peaks_on_smoothed_data_with_baseline(pd_data_corr_df, \n",
    "                                          smoothed_data, peak_indices, \n",
    "                                          pd_data_corr_df_baselinetocheck, \n",
    "                                          link_save + '\\CFU_Peaks_calc_smooth', fs_value)\n",
    "plot_peak_density_per_cfu(peak_indices, fs=fs_value, output_dir=link_save + '\\CFU_Peaks_dencity')\n",
    "save_cfu_analysis_with_report_v2(\n",
    "    pd_data_corr_df, smoothed_data, pd_data_corr_df_baselinetocheck, peak_indices, link_save,\n",
    "    link_folder, link_file_mat, link_save,\n",
    "    sigma_value, deg_value, fs_value, height_value, prominence_value, distance_value)\n",
    "plot_combined_smoothed_and_peak_density(\n",
    "     pd_data_corr_df, smoothed_data, peak_indices, fps=fs_value, \n",
    "     height_value=height_value, prominence_value=prominence_value, distance_value=distance_value, sigma_value=sigma_value,\n",
    "     output_path=link_save)\n",
    "overlap_df = compare_peak_times(\n",
    "     peak_indices, tolerance_frames=1, fps=fs_value, output_path=link_save\n",
    " )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81340f61-5c89-452e-81d0-cf3c2ccdc6b7",
   "metadata": {},
   "source": [
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1204a766-4521-4162-94d6-00163a74546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved high-overlap plot for Mask_10 and Mask_12 to E:\\Data\\analysis_cm005\\Save_241202_CM005_rec2_unit5_32_crop_AQuA2\\overlap_Mask_10_Mask_12.html\n",
      "Saved high-overlap plot for Mask_11 and Mask_12 to E:\\Data\\analysis_cm005\\Save_241202_CM005_rec2_unit5_32_crop_AQuA2\\overlap_Mask_11_Mask_12.html\n",
      "Saved high-overlap plot for Mask_12 and Mask_10 to E:\\Data\\analysis_cm005\\Save_241202_CM005_rec2_unit5_32_crop_AQuA2\\overlap_Mask_12_Mask_10.html\n",
      "Saved high-overlap plot for Mask_12 and Mask_11 to E:\\Data\\analysis_cm005\\Save_241202_CM005_rec2_unit5_32_crop_AQuA2\\overlap_Mask_12_Mask_11.html\n"
     ]
    }
   ],
   "source": [
    "plot_high_overlap_pairs(pd_data_corr_df, smoothed_data, peak_indices, overlap_df, 20, fs_value, link_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4061b1ae-d09b-4e3e-8b10-350f7e7e4f76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
