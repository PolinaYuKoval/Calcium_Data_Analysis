{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "455b3ba7-7f53-4299-9012-53c8a304b82d",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- adjust links according to your file system\n",
    "- check the existing folders to save the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfafd523-f334-4b2e-bf8f-6abffdd4b08a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee50b826-1e7d-496a-9e8a-0f4df32e7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import peakutils \n",
    "\n",
    "import scipy\n",
    "from scipy.signal import find_peaks, butter, filtfilt\n",
    "import scipy.io\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.stats import norm\n",
    "\n",
    "import os\n",
    "\n",
    "import tifffile as tiff\n",
    "from tifffile import imshow\n",
    "\n",
    "from ipywidgets import interactive, fixed, IntSlider, Checkbox\n",
    "\n",
    "import skimage.io as skio\n",
    "from skimage import exposure\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.filters import try_all_threshold\n",
    "from skimage.filters import threshold_triangle, threshold_li, gaussian\n",
    "from skimage.morphology import remove_small_objects, binary_dilation, binary_erosion, label\n",
    "from skimage.color import label2rgb\n",
    "\n",
    "import cv2\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from ipywidgets import interactive, IntSlider\n",
    "from IPython.display import display\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e144e6c7-e554-4602-95d0-d5d25ff369e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8a56e4-ec60-4db1-91fc-76862b06e151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfu_to_tif(cfu_link, cfu_global, path_to_save):\n",
    "    \"\"\"\n",
    "    Converts a CFU MATLAB data to a TIFF image and saves it.\n",
    "    \"\"\"\n",
    "    mat = scipy.io.loadmat(cfu_link)\n",
    "    os.makedirs(path_to_save, exist_ok=True)\n",
    "    cfu_i = mat[cfu_global]\n",
    "    cfu_info_normalized = (cfu_i / np.max(cfu_i) * 255).astype(np.uint8)\n",
    "    path_to_save = os.path.join(path_to_save, cfu_global + '.tiff')\n",
    "    image = Image.fromarray(cfu_info_normalized)\n",
    "    image.save(path_to_save)\n",
    "    return path_to_save\n",
    "\n",
    "def cfu_to_tif_global(cfu_link, path_to_save, cfu_global = 'cfuInfo1', index_2=2):\n",
    "    \"\"\"\n",
    "    Converts a CFU MATLAB data to a TIFF image and saves it.\n",
    "    \"\"\"\n",
    "    mat = scipy.io.loadmat(cfu_link)\n",
    "    os.makedirs(path_to_save, exist_ok=True)\n",
    "    df_test = {}\n",
    "    mask_name = 'Mask_'\n",
    "    for i in range(mat[cfu_global].shape[0]):\n",
    "        a = Image.fromarray((mat['cfuInfo1'][i][index_2] / np.max( mat['cfuInfo1'][i][index_2]) * 255).astype(np.uint8))\n",
    "        df_test['Mask_' + str(i)] = a\n",
    "        path = os.path.join(path_to_save, cfu_global + mask_name + str(i) + '.tiff')\n",
    "        image = a\n",
    "        image.save(path)\n",
    "    return \n",
    "def get_data_global(cfu_link, path_to_save, cfu_global = 'cfuInfo1'):\n",
    "    \"\"\"\n",
    "    Converts a CFU MATLAB data to a TIFF image and saves it.\n",
    "    \"\"\"\n",
    "    mat = scipy.io.loadmat(cfu_link)\n",
    "    os.makedirs(path_to_save, exist_ok=True)\n",
    "    df_data = {}\n",
    "    df_data_df = {}\n",
    "    mask_name = 'Mask_'\n",
    "    for i in range(mat[cfu_global].shape[0]):\n",
    "        df_data['Mask_' + str(i)] = mat['cfuInfo1'][i][4][0]\n",
    "        df_data_df['Mask_' + str(i)] = mat['cfuInfo1'][i][5][0]\n",
    "    #df_data = pd.DataFrame(df_data)\n",
    "    #df_data_df = pd.DataFrame(df_data_df)\n",
    "    return df_data, df_data_df\n",
    "def df_trans_ren(df, global_coef):\n",
    "    \"\"\"\n",
    "    Transposes a DataFrame and renames columns with a prefix.\n",
    "    \"\"\"\n",
    "    df_transposed = df.T\n",
    "    df_transposed.columns = [global_coef + f\"{i+1}\" for i in range(df_transposed.shape[1])]\n",
    "    return df_transposed\n",
    "\n",
    "\n",
    "def calculate_baseline(df, sigma=10, deg=5):\n",
    "    \"\"\"\n",
    "    Calculates baselines for each column in the DataFrame.\n",
    "    \"\"\"\n",
    "    baselines = {}\n",
    "    for col in df.columns:\n",
    "        smoothed_data = gaussian_filter(df[col].values, sigma=sigma)\n",
    "        baselines[col] = peakutils.baseline(smoothed_data, deg=deg)\n",
    "    return pd.DataFrame(baselines)\n",
    "\n",
    "def plot_and_save(df, baselines, output_dir, combined_filename=\"all_cfus_combined_graph.html\"):\n",
    "    \"\"\"\n",
    "    Plots and saves individual CFU graphs and a combined graph.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig_combined = go.Figure()\n",
    "    for col in df.columns:\n",
    "        cfu_data = df[col].values\n",
    "        baseline = baselines[col].values\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=cfu_data, mode='lines', name=f\"CFU {col}\", line=dict(color=\"blue\")))\n",
    "        fig.add_trace(go.Scatter(y=baseline, mode='lines', name=f\"Baseline {col}\", line=dict(color=\"red\", dash=\"dash\")))\n",
    "        fig.update_layout(\n",
    "            title=f\"Graph for CFU {col} with Baseline\",\n",
    "            xaxis_title=\"Index\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        output_path = os.path.join(output_dir, f\"cfu_{col}_graph.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved interactive graph for CFU {col} as {output_path}\")\n",
    "        fig_combined.add_trace(go.Scatter(y=cfu_data, mode='lines', name=f\"CFU {col}\"))\n",
    "        fig_combined.add_trace(go.Scatter(y=baseline, mode='lines', name=f\"Baseline {col}\", line=dict(dash=\"dash\")))\n",
    "    combined_output_path = os.path.join(output_dir, combined_filename)\n",
    "    fig_combined.update_layout(\n",
    "        title=\"Combined Graph for All CFUs with Baselines\",\n",
    "        xaxis_title=\"Index\",\n",
    "        yaxis_title=\"Intensity\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_combined.write_html(combined_output_path)\n",
    "    print(f\"Saved combined graph as {combined_output_path}\")\n",
    "\n",
    "def detect_peaks(df, height=None, prominence=None, distance=None):\n",
    "    \"\"\"\n",
    "    Detects peaks in each column of a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with Delta F/F data.\n",
    "        height (float, optional): Minimum height of peaks.\n",
    "        prominence (float, optional): Minimum prominence of peaks.\n",
    "        distance (int, optional): Minimum distance between peaks.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with column names as keys and detected peak indices as values.\n",
    "        pd.DataFrame: A DataFrame with the number of peaks detected for each CFU.\n",
    "    \"\"\"\n",
    "    peak_indices = {}\n",
    "    peak_counts = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        data = df[col].values\n",
    "        peaks, _ = find_peaks(data, height=height, prominence=prominence, distance=distance)\n",
    "        peak_indices[col] = peaks\n",
    "        peak_counts[col] = len(peaks)\n",
    "    peak_counts_df = pd.DataFrame(list(peak_counts.items()), columns=[\"CFU\", \"Peak Count\"])\n",
    "    peak_counts_df.set_index(\"CFU\", inplace=True)\n",
    "    \n",
    "    return peak_indices, peak_counts_df\n",
    "\n",
    "def plot_peaks(df, peak_indices, output_dir):\n",
    "    \"\"\"\n",
    "    Plots data with detected peaks for each CFU.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        data = df[col].values\n",
    "        peaks = peak_indices[col]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=data, mode='lines', name=f\"CFU {col}\"))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=peaks, y=data[peaks], mode='markers', name=f\"Peaks {col}\",\n",
    "            marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Detected Peaks for CFU {col}\",\n",
    "            xaxis_title=\"Index\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        output_path = os.path.join(output_dir, f\"cfu_{col}_peaks.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved peak detection graph for CFU {col} to {output_path}\")\n",
    "\n",
    "def low_pass_filter(data, cutoff, fs, order=4):\n",
    "    \"\"\"\n",
    "    Apply a low-pass Butterworth filter to the data.\n",
    "\n",
    "    Parameters:\n",
    "        data (np.ndarray): The input data to filter.\n",
    "        cutoff (float): The cutoff frequency in Hz.\n",
    "        fs (float): The sampling frequency in Hz.\n",
    "        order (int): The order of the filter.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: The filtered data.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs  # Nyquist frequency\n",
    "    normal_cutoff = cutoff / nyquist  # Normalize cutoff frequency\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)  # Design filter\n",
    "    filtered_data = filtfilt(b, a, data)  # Apply filter\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def detect_peaks_on_smoothed_data(df, fs=30, cutoff=5, height=None, prominence=None, distance=None):\n",
    "    \"\"\"\n",
    "    Detect peaks on smoothed data using a low-pass filter for noise reduction.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with original Delta F/F data.\n",
    "        fs (float): Sampling frequency in Hz (default 30 Hz).\n",
    "        cutoff (float): Cutoff frequency for the low-pass filter in Hz (default 5 Hz).\n",
    "        height (float, optional): Minimum height of peaks.\n",
    "        prominence (float, optional): Minimum prominence of peaks.\n",
    "        distance (int, optional): Minimum distance between peaks.\n",
    "        \n",
    "    Returns:\n",
    "        dict: A dictionary with column names as keys and detected peak indices as values.\n",
    "        dict: A dictionary with column names as keys and smoothed data as values.\n",
    "        pd.DataFrame: A DataFrame with the number of peaks detected for each CFU.\n",
    "    \"\"\"\n",
    "    peak_indices = {}\n",
    "    smoothed_data_dict = {}\n",
    "    peak_counts = {}\n",
    "\n",
    "    for col in df.columns:\n",
    "        smoothed_data = low_pass_filter(df[col].values, cutoff=cutoff, fs=fs)\n",
    "        smoothed_data_dict[col] = smoothed_data\n",
    "        peaks, _ = find_peaks(smoothed_data, height=height, prominence=prominence, distance=distance)\n",
    "        peak_indices[col] = peaks\n",
    "        peak_counts[col] = len(peaks)\n",
    "    peak_counts_df = pd.DataFrame(list(peak_counts.items()), columns=[\"CFU\", \"Peak Count\"])\n",
    "    peak_counts_df.set_index(\"CFU\", inplace=True)\n",
    "    \n",
    "    return peak_indices, smoothed_data_dict, peak_counts_df\n",
    "\n",
    "def plot_peaks_on_smoothed_data_with_baseline(df, smoothed_data_dict, peak_indices, baseline_dict, output_dir, fps):\n",
    "    \"\"\"\n",
    "    Plots smoothed data, original df, baseline, and detected peaks for each CFU in seconds.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original data for reference.\n",
    "        smoothed_data_dict (dict): Dictionary of smoothed data.\n",
    "        peak_indices (dict): Dictionary of detected peaks.\n",
    "        baseline_dict (dict): Dictionary of baseline values for each CFU.\n",
    "        output_dir (str): Directory to save the plots.\n",
    "        fps (float): Frames per second of the data.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig_combined = go.Figure()\n",
    "\n",
    "    for col in df.columns:\n",
    "        original_data = df[col].values\n",
    "        smoothed_data = smoothed_data_dict[col]\n",
    "        peaks = peak_indices[col]\n",
    "        baseline = baseline_dict[col]\n",
    "        time_seconds = np.arange(len(original_data)) / fps  # Convert frame numbers to seconds\n",
    "\n",
    "        # Create the plot\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(x=time_seconds, y=original_data, mode='lines', name=f\"Original CFU {col}\", line=dict(color=\"blue\")))\n",
    "        fig.add_trace(go.Scatter(x=time_seconds, y=smoothed_data, mode='lines', name=f\"Smoothed CFU {col}\", line=dict(color=\"green\")))\n",
    "        fig.add_trace(go.Scatter(x=time_seconds, y=baseline, mode='lines', name=f\"Baseline {col}\", line=dict(color=\"orange\", dash='dash')))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=time_seconds[peaks], y=smoothed_data[peaks], mode='markers', name=f\"Peaks {col}\",\n",
    "            marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Smoothed Data with Detected Peaks for CFU {col}\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"cfu_{col}_smoothed_peaks.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved peak detection graph for CFU {col} to {output_path}\")\n",
    "\n",
    "        # Add to combined plot\n",
    "        fig_combined.add_trace(go.Scatter(x=time_seconds, y=smoothed_data, mode='lines', name=f\"Smoothed CFU {col}\"))\n",
    "        fig_combined.add_trace(go.Scatter(\n",
    "            x=time_seconds[peaks], y=smoothed_data[peaks], mode='markers', name=f\"Peaks {col} ({len(peaks)})\"\n",
    "        ))\n",
    "        fig_combined.add_trace(go.Scatter(x=time_seconds, y=baseline, mode='lines', name=f\"Baseline {col} ({col})\"))\n",
    "\n",
    "    combined_output_path = os.path.join(output_dir, \"all_cfus_smoothed_peaks_combined.html\")\n",
    "    fig_combined.update_layout(\n",
    "        title=\"Smoothed Data with Detected Peaks for All CFUs\",\n",
    "        xaxis_title=\"Time (s)\",\n",
    "        yaxis_title=\"Intensity\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_combined.write_html(combined_output_path)\n",
    "    print(f\"Saved combined peak detection graph to {combined_output_path}\")\n",
    "\n",
    "\n",
    "def plot_peak_density_per_cfu(peak_indices, fs, output_dir=\"peak_density_plots\", bins=30):\n",
    "    \"\"\"\n",
    "    Plots the density of detected peaks per second for each CFU and saves as HTML.\n",
    "\n",
    "    Parameters:\n",
    "        peak_indices (dict): A dictionary with CFU names as keys and detected peak indices as values.\n",
    "        fs (float): Sampling frequency in Hz.\n",
    "        output_dir (str): Directory to save the HTML plots.\n",
    "        bins (int): Number of bins for the histogram.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "    for cfu, indices in peak_indices.items():\n",
    "        # Convert peak indices to time (seconds)\n",
    "        peak_times = np.array(indices) / fs\n",
    "\n",
    "        # Create histogram bins\n",
    "        peak_counts, bin_edges = np.histogram(peak_times, bins=bins)\n",
    "\n",
    "        # Create the Plotly bar plot\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=bin_edges[:-1],\n",
    "            y=peak_counts,\n",
    "            width=(bin_edges[1] - bin_edges[0]),\n",
    "            marker=dict(color=\"blue\", opacity=0.7),\n",
    "            name=\"Peak Density\"\n",
    "        ))\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f\"Peak Density for {cfu}\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis_title=\"Peak Density (Peaks per Bin)\",\n",
    "            template=\"plotly_white\",\n",
    "            bargap=0.1\n",
    "        )\n",
    "\n",
    "        # Save the plot as HTML\n",
    "        output_path = os.path.join(output_dir, f\"peak_density_{cfu}.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved peak density plot for {cfu} to {output_path}\")\n",
    "        \n",
    "'''def plot_peaks_on_smoothed_data_with_baseline(df, smoothed_data_dict, peak_indices, baseline_dict, output_dir):\n",
    "    \"\"\"\n",
    "    Plots smoothed data, original df, baseline, and detected peaks for each CFU.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original data for reference.\n",
    "        smoothed_data_dict (dict): Dictionary of smoothed data.\n",
    "        peak_indices (dict): Dictionary of detected peaks.\n",
    "        baseline_dict (dict): Dictionary of baseline values for each CFU.\n",
    "        output_dir (str): Directory to save the plots.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig_combined = go.Figure()\n",
    "\n",
    "    for col in df.columns:\n",
    "        original_data = df[col].values\n",
    "        smoothed_data = smoothed_data_dict[col]\n",
    "        peaks = peak_indices[col]\n",
    "        baseline = baseline_dict[col]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=original_data, mode='lines', name=f\"Original CFU {col}\", line=dict(color=\"blue\")))\n",
    "        fig.add_trace(go.Scatter(y=smoothed_data, mode='lines', name=f\"Smoothed CFU {col}\", line=dict(color=\"green\")))\n",
    "        fig.add_trace(go.Scatter(y=baseline, mode='lines', name=f\"Baseline {col}\", line=dict(color=\"orange\", dash='dash')))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=peaks, y=smoothed_data[peaks], mode='markers', name=f\"Peaks {col}\",\n",
    "            marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Smoothed Data with Detected Peaks for CFU {col}\",\n",
    "            xaxis_title=\"Index\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "\n",
    "        output_path = os.path.join(output_dir, f\"cfu_{col}_smoothed_peaks.html\")\n",
    "        fig.write_html(output_path)\n",
    "        print(f\"Saved peak detection graph for CFU {col} to {output_path}\")\n",
    "        fig_combined.add_trace(go.Scatter(y=smoothed_data, mode='lines', name=f\"Smoothed CFU {col}\"))\n",
    "        fig_combined.add_trace(go.Scatter(\n",
    "            x=peaks, y=smoothed_data[peaks], mode='markers', name=f\"Peaks {col} ({len(peaks)})\"\n",
    "        ))\n",
    "        fig_combined.add_trace(go.Scatter(y=baseline, mode='lines', name=f\"Baseline {col} ({col})\"))\n",
    "    combined_output_path = os.path.join(output_dir, \"all_cfus_smoothed_peaks_combined.html\")\n",
    "    fig_combined.update_layout(\n",
    "        title=\"Smoothed Data with Detected Peaks for All CFUs\",\n",
    "        xaxis_title=\"Index\",\n",
    "        yaxis_title=\"Intensity\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_combined.write_html(combined_output_path)\n",
    "    print(f\"Saved combined peak detection graph to {combined_output_path}\")'''\n",
    "\n",
    "\n",
    "def calculate_intensities(tiff_file, mask_folder, output_csv):\n",
    "    \"\"\"\n",
    "    Calculate frame-wise intensities for each mask and save as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        tiff_file (str): Path to the multi-frame TIFF file.\n",
    "        mask_folder (str): Path to the folder containing mask files as TIFFs.\n",
    "        output_csv (str): Path to save the intensity DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing frame-wise intensities for each mask.\n",
    "    \"\"\"\n",
    "    with tiff.TiffFile(tiff_file) as tif:\n",
    "        tiff_data = tif.asarray()\n",
    "\n",
    "    print(f\"Loaded TIFF with shape {tiff_data.shape} (frames, height, width)\")\n",
    "    num_frames = tiff_data.shape[0]\n",
    "    intensity_data = pd.DataFrame(index=range(num_frames))\n",
    "    for mask_file in os.listdir(mask_folder):\n",
    "        if not mask_file.endswith('.tiff'):\n",
    "            continue\n",
    "        mask_path = os.path.join(mask_folder, mask_file)\n",
    "        with tiff.TiffFile(mask_path) as mask_tif:\n",
    "            mask = mask_tif.asarray().astype(bool)\n",
    "        if mask.shape != tiff_data.shape[1:]:\n",
    "            raise ValueError(f\"Mask {mask_file} shape {mask.shape} does not match TIFF shape {tiff_data.shape[1:]}\")\n",
    "        frame_intensities = [np.mean(frame[mask]) for frame in tiff_data]\n",
    "        mask_name = os.path.splitext(mask_file)[0]\n",
    "        intensity_data[mask_name] = frame_intensities\n",
    "    intensity_data.to_csv(output_csv)\n",
    "    print(f\"Saved intensity data to {output_csv}\")\n",
    "\n",
    "    return intensity_data\n",
    "    \n",
    "def crop_tiff_dimensions(tiff_data, crop_pixels=5):\n",
    "    \"\"\"\n",
    "    Crop the second and third dimensions (height and width) of a TIFF file.\n",
    "\n",
    "    Parameters:\n",
    "        tiff_data (np.ndarray): Original TIFF data (frames, height, width).\n",
    "        crop_pixels (int): Number of pixels to crop from each side.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Cropped TIFF data.\n",
    "    \"\"\"\n",
    "    return tiff_data[:, crop_pixels:-crop_pixels, crop_pixels:-crop_pixels]\n",
    "\n",
    "\n",
    "def calculate_dff(intensity_data):\n",
    "    \"\"\"\n",
    "    Calculate Delta F/F for the given intensity data using column-wise minimum as baseline.\n",
    "\n",
    "    Parameters:\n",
    "        intensity_data (pd.DataFrame): Frame-wise intensity data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing Delta F/F values.\n",
    "    \"\"\"\n",
    "    baselines = intensity_data.min(axis=0)\n",
    "    dff = (intensity_data - baselines) / baselines\n",
    "    return dff\n",
    "\n",
    "'''\n",
    "def detect_peaks(dff_data, height=None, prominence=None, distance=None):\n",
    "    \"\"\"\n",
    "    Detect peaks in Delta F/F data for each mask.\n",
    "\n",
    "    Parameters:\n",
    "        dff_data (pd.DataFrame): Delta F/F DataFrame.\n",
    "        height (float, optional): Minimum peak height.\n",
    "        prominence (float, optional): Minimum prominence of peaks.\n",
    "        distance (int, optional): Minimum distance between peaks.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with column names as keys and detected peak indices as values.\n",
    "    \"\"\"\n",
    "    peak_indices = {}\n",
    "\n",
    "    for col in dff_data.columns:\n",
    "        # Detect peaks\n",
    "        peaks, _ = find_peaks(dff_data[col].values, height=height, prominence=prominence, distance=distance)\n",
    "        peak_indices[col] = peaks\n",
    "\n",
    "    return peak_indices\n",
    "'''\n",
    "\n",
    "def plot_dff_and_peaks(dff_data, peak_indices, output_dir):\n",
    "    \"\"\"\n",
    "    Plot Delta F/F data and detected peaks for each mask.\n",
    "\n",
    "    Parameters:\n",
    "        dff_data (pd.DataFrame): Delta F/F DataFrame.\n",
    "        peak_indices (dict): Dictionary of detected peak indices.\n",
    "        output_dir (str): Directory to save the plots.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig_combined = go.Figure()\n",
    "\n",
    "    for col in dff_data.columns:\n",
    "        dff_values = dff_data[col].values\n",
    "        peaks = peak_indices[col]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=dff_values, mode='lines', name=f\"Delta F/F {col}\", line=dict(color=\"blue\")))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=peaks, y=dff_values[peaks], mode='markers', name=f\"Peaks {col}\",\n",
    "            marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Delta F/F and Peaks for {col}\",\n",
    "            xaxis_title=\"Frame\",\n",
    "            yaxis_title=\"Delta F/F\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        fig.write_html(os.path.join(output_dir, f\"{col}_dff_peaks.html\"))\n",
    "        fig_combined.add_trace(go.Scatter(y=dff_values, mode='lines', name=f\"Delta F/F {col}\"))\n",
    "        fig_combined.add_trace(go.Scatter(\n",
    "            x=peaks, y=dff_values[peaks], mode='markers', name=f\"Peaks {col} ({len(peaks)})\"\n",
    "        ))\n",
    "    combined_output_path = os.path.join(output_dir, \"combined_dff_peaks.html\")\n",
    "    fig_combined.update_layout(\n",
    "        title=\"Combined Delta F/F and Peaks for All Masks\",\n",
    "        xaxis_title=\"Frame\",\n",
    "        yaxis_title=\"Delta F/F\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_combined.write_html(combined_output_path)\n",
    "    print(f\"Saved combined Delta F/F and peaks plot to {combined_output_path}\")\n",
    "\n",
    "def plot_and_save_intensities(intensity_data, smoothed_data, peak_indices, output_dir):\n",
    "    \"\"\"\n",
    "    Plot and save intensity and peak detection results.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig_combined = go.Figure()\n",
    "\n",
    "    for col in intensity_data.columns:\n",
    "        original_data = intensity_data[col].values\n",
    "        smoothed = smoothed_data[col]\n",
    "        peaks = peak_indices[col]\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(y=original_data, mode='lines', name=f\"Original {col}\", line=dict(color=\"blue\")))\n",
    "        fig.add_trace(go.Scatter(y=smoothed, mode='lines', name=f\"Smoothed {col}\", line=dict(color=\"green\")))\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=peaks, y=smoothed[peaks], mode='markers', name=f\"Peaks {col}\",\n",
    "            marker=dict(color='red', size=8)\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=f\"Intensity and Peaks for {col}\",\n",
    "            xaxis_title=\"Frame\",\n",
    "            yaxis_title=\"Intensity\",\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        fig.write_html(os.path.join(output_dir, f\"{col}_peaks.html\"))\n",
    "        fig_combined.add_trace(go.Scatter(y=smoothed, mode='lines', name=f\"Smoothed {col}\"))\n",
    "        fig_combined.add_trace(go.Scatter(\n",
    "            x=peaks, y=smoothed[peaks], mode='markers', name=f\"Peaks {col} ({len(peaks)})\"\n",
    "        ))\n",
    "    combined_output_path = os.path.join(output_dir, \"combined_peaks.html\")\n",
    "    fig_combined.update_layout(\n",
    "        title=\"Combined Intensity and Peaks for All Masks\",\n",
    "        xaxis_title=\"Frame\",\n",
    "        yaxis_title=\"Intensity\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    fig_combined.write_html(combined_output_path)\n",
    "    print(f\"Saved combined intensity and peaks plot to {combined_output_path}\")\n",
    "\n",
    "def save_cfu_analysis_with_report_v2(\n",
    "    df, smoothed_data_dict, baseline_dict, peak_indices, output_dir,\n",
    "    link_folder, link_file_mat, link_save,\n",
    "    sigma_value, deg_value, fs_value, height_value, prominence_value, distance_value\n",
    "):\n",
    "    \"\"\"\n",
    "    Saves the CFU analysis results to CSV files and generates a detailed TXT report.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original CFU DataFrame.\n",
    "        smoothed_data_dict (dict): Dictionary containing smoothed data for each CFU.\n",
    "        baseline_dict (dict): Dictionary containing baseline data for each CFU.\n",
    "        peak_indices (dict): Dictionary containing indices of detected peaks for each CFU.\n",
    "        output_dir (str): Directory to save the CSV files and report.\n",
    "        link_folder (str): Folder containing the data.\n",
    "        link_file_mat (str): Path to the original MAT file.\n",
    "        link_save (str): Folder where files are saved.\n",
    "        sigma_value (float): Smoothing sigma value.\n",
    "        deg_value (int): Degree of baseline correction.\n",
    "        fs_value (float): Frames per second of the data.\n",
    "        height_value (float): Minimum peak height for detection.\n",
    "        prominence_value (float): Minimum peak prominence for detection.\n",
    "        distance_value (int): Minimum distance between peaks.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    cfu_analysis_df = pd.DataFrame()\n",
    "\n",
    "    # Generate the main analysis DataFrame\n",
    "    for cfu in df.columns:\n",
    "        original_data = df[cfu]\n",
    "        smoothed_data = smoothed_data_dict[cfu]\n",
    "        baseline_data = baseline_dict[cfu]\n",
    "        peak_mask = np.zeros(len(smoothed_data), dtype=int)\n",
    "        peak_mask[peak_indices[cfu]] = 1  # Mark peaks as 1, others as 0\n",
    "\n",
    "        cfu_data = pd.DataFrame({\n",
    "            \"CFU\": cfu,\n",
    "            \"Original CFU Data\": original_data,\n",
    "            \"Smoothed CFU Data\": smoothed_data,\n",
    "            \"Baseline CFU Data\": baseline_data,\n",
    "            \"Detected Peaks (Smoothed)\": peak_mask\n",
    "        })\n",
    "        cfu_analysis_df = pd.concat([cfu_analysis_df, cfu_data], ignore_index=True)\n",
    "\n",
    "    # Save the main CFU analysis DataFrame\n",
    "    cfu_analysis_csv_path = os.path.join(output_dir, \"cfu_analysis.csv\")\n",
    "    cfu_analysis_df.to_csv(cfu_analysis_csv_path, index=False)\n",
    "    print(f\"Saved CFU analysis to {cfu_analysis_csv_path}\")\n",
    "\n",
    "    # Generate the peaks summary DataFrame with counts\n",
    "    peaks_data = []\n",
    "    for cfu, indices in peak_indices.items():\n",
    "        peaks_data.append({\"CFU\": cfu, \"Detected Peak Count\": len(indices)})\n",
    "\n",
    "    peaks_df = pd.DataFrame(peaks_data)\n",
    "\n",
    "    # Save the peaks summary DataFrame\n",
    "    peaks_csv_path = os.path.join(output_dir, \"detected_peaks_summary.csv\")\n",
    "    peaks_df.to_csv(peaks_csv_path, index=False)\n",
    "    print(f\"Saved detected peaks summary to {peaks_csv_path}\")\n",
    "\n",
    "    # Generate a report as a TXT file\n",
    "    report_path = os.path.join(output_dir, \"analysis_report.txt\")\n",
    "    with open(report_path, \"w\") as report_file:\n",
    "        report_file.write(\"Analysis Report\\n\")\n",
    "        report_file.write(\"=\" * 40 + \"\\n\\n\")\n",
    "\n",
    "        # Write metadata\n",
    "        report_file.write(\"Links and Paths:\\n\")\n",
    "        report_file.write(f\"Data Folder: {link_folder}\\n\")\n",
    "        report_file.write(f\"MAT File: {link_file_mat}\\n\")\n",
    "        report_file.write(f\"Save Folder: {link_save}\\n\\n\")\n",
    "\n",
    "        # Write coefficients\n",
    "        report_file.write(\"Coefficients Used:\\n\")\n",
    "        report_file.write(f\"Smoothing Sigma Value: {sigma_value}\\n\")\n",
    "        report_file.write(f\"Baseline Degree: {deg_value}\\n\")\n",
    "        report_file.write(f\"Frames Per Second (FPS): {fs_value}\\n\")\n",
    "        report_file.write(f\"Peak Detection Height: {height_value}\\n\")\n",
    "        report_file.write(f\"Peak Detection Prominence: {prominence_value}\\n\")\n",
    "        report_file.write(f\"Peak Detection Distance: {distance_value}\\n\\n\")\n",
    "\n",
    "        # Write FPS and DataFrame length\n",
    "        report_file.write(f\"Total Length of Data (Mask_0): {len(df['Mask_0'])}\\n\")\n",
    "\n",
    "        # Write peaks summary\n",
    "        report_file.write(\"\\nNumber of Peaks per Mask:\\n\")\n",
    "        for cfu, indices in peak_indices.items():\n",
    "            report_file.write(f\"- {cfu}: {len(indices)} peaks\\n\")\n",
    "\n",
    "        # Write file paths\n",
    "        report_file.write(\"\\nFiles Saved:\\n\")\n",
    "        report_file.write(f\"- CFU Analysis: {cfu_analysis_csv_path}\\n\")\n",
    "        report_file.write(f\"- Peaks Summary: {peaks_csv_path}\\n\")\n",
    "\n",
    "        # Add date and time of analysis\n",
    "        report_file.write(\"\\nDate and Time of Analysis:\\n\")\n",
    "        report_file.write(f\"{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "        # Add output folder location\n",
    "        report_file.write(\"\\nOutput Folder:\\n\")\n",
    "        report_file.write(f\"{output_dir}\\n\")\n",
    "\n",
    "    print(f\"Saved analysis report to {report_path}\")\n",
    "\n",
    "def plot_combined_smoothed_and_peak_density(\n",
    "    df, smoothed_data_dict, peak_indices, fps, height_value, prominence_value, distance_value, sigma_value, output_path\n",
    "):\n",
    "    \"\"\"\n",
    "    Plots the smoothed data with detected peaks, and aligns it with a barplot of peak density.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Original Delta F/F data.\n",
    "        smoothed_data_dict (dict): Dictionary of smoothed data for each CFU.\n",
    "        peak_indices (dict): Dictionary of detected peaks for each CFU.\n",
    "        fps (float): Sampling frequency in Hz.\n",
    "        height_value (float): Minimum height of peaks for detection.\n",
    "        prominence_value (float): Minimum prominence of peaks.\n",
    "        distance_value (int): Minimum distance between peaks.\n",
    "        sigma_value (float): Smoothing coefficient.\n",
    "        output_path (str): Path to save the combined plot.\n",
    "    \"\"\"\n",
    "    for cfu in df.columns:\n",
    "        # Original data, smoothed data, and peaks\n",
    "        original_data = df[cfu].values\n",
    "        smoothed_data = smoothed_data_dict[cfu]\n",
    "        peaks = peak_indices[cfu]\n",
    "        time_seconds = np.arange(len(original_data)) / fps  # Convert frame numbers to seconds\n",
    "\n",
    "        # Calculate peak density\n",
    "        peak_times = np.array(peaks) / fps\n",
    "        bin_edges = np.arange(0, time_seconds[-1] + 1, 1)  # Align bins to time axis\n",
    "        peak_counts, bin_edges = np.histogram(peak_times, bins=bin_edges)\n",
    "\n",
    "        # Create subplots\n",
    "        fig = sp.make_subplots(\n",
    "            rows=2, cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.1,\n",
    "            row_heights=[0.7, 0.3],\n",
    "            subplot_titles=(f\"Smoothed Data with Peaks for {cfu}\", \"Peak Density\")\n",
    "        )\n",
    "\n",
    "        # Add smoothed data and peaks to the first subplot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=time_seconds, y=original_data, mode='lines', name=\"Original Data\", line=dict(color=\"blue\", width=1)),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=time_seconds, y=smoothed_data, mode='lines', name=\"Smoothed Data\", line=dict(color=\"green\", width=2)),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=time_seconds[peaks], y=smoothed_data[peaks], mode='markers', name=\"Detected Peaks\",\n",
    "                       marker=dict(color='red', size=8)),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "        # Add barplot of peak density to the second subplot\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=bin_edges[:-1], y=peak_counts, width=1,  # Ensure bar width aligns with bins\n",
    "                name=\"Peak Density\", marker=dict(color=\"blue\", opacity=0.7)\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f\"Combined Smoothed Data and Peak Density for {cfu}\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis=dict(title=\"Intensity\"),\n",
    "            yaxis2=dict(title=\"Peak Density (Peaks per Bin)\"),\n",
    "            template=\"plotly_white\",\n",
    "            legend_title=\"Input Parameters\",\n",
    "            annotations=[\n",
    "                dict(\n",
    "                    text=(\n",
    "                        f\"<b>Parameters:</b><br>\"\n",
    "                        f\"FPS: {fps}<br>\"\n",
    "                        f\"Height: {height_value}<br>\"\n",
    "                        f\"Prominence: {prominence_value}<br>\"\n",
    "                        f\"Distance: {distance_value}<br>\"\n",
    "                        f\"Smoothing Sigma: {sigma_value}\"\n",
    "                    ),\n",
    "                    x=1.1, y=1.2, showarrow=False, xref=\"paper\", yref=\"paper\", align=\"left\"\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Save the plot\n",
    "        fig.write_html(output_path + f\"/combined_smoothed_peak_density_{cfu}.html\")\n",
    "        print(f\"Saved combined plot for {cfu} to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcd282-ea16-4a56-880c-30be934dc70f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362713a1-6836-469b-b6e4-29bdf177535f",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_folder = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\All_CFUs.mat'\n",
    "link_save = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\Save'\n",
    "link_file = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop4_1.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc46dd2-9777-457c-b4f4-f5d2921e185d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe53121c-0522-46b3-8418-2d9eed4bd3ce",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54886d0-1399-4fb7-a8c5-f6174c67a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(link_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04bbdea-beb5-49e2-8bf9-606e2d350ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_base = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\CFU_'\n",
    "links_list = []\n",
    "cfu_base = r'cfuInfo1'\n",
    "cfu_list = []\n",
    "path_to_s = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\path_'\n",
    "for i in range(9):\n",
    "    links_list.append(link_base + str(i+1))\n",
    "    cfu_list.append(cfu_base + str(i+1))\n",
    "print('CFU list: ' + str(cfu_list))\n",
    "print('links list: ' + str(links_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3842d5bd-bfe5-4d40-8cf6-3d9e01aa0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    cfu_to_tif(links_list[i], cfu_list[i], path_to_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f7d6b-ea7f-4b70-a062-33da93155e4f",
   "metadata": {},
   "source": [
    "Save all plotted intensities from the All_CFUs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689fa79-418d-499e-8465-3994c89becbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cfus = scipy.io.loadmat(link_folder)['All_CFUs']\n",
    "output_dir = link_save + '\\All_CFUs_'  # Set your desired output directory\n",
    "\n",
    "for i, row in enumerate(all_cfus):\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=row, mode='lines', name=f\"Row {i + 1}\"))\n",
    "    fig.update_layout(\n",
    "        title=f\"Graph for Row {i + 1}\",\n",
    "        xaxis_title=\"Index\",\n",
    "        yaxis_title=\"Intensity\",\n",
    "        template=\"plotly_white\"\n",
    "    )\n",
    "    output_path = output_dir + f\"row_{i + 1}_graph.html\"\n",
    "    fig.write_html(output_path)\n",
    "    print(f\"Saved interactive graph for row {i + 1} as {output_path}\")\n",
    "\n",
    "fig_combined = go.Figure()\n",
    "for i, row in enumerate(all_cfus):\n",
    "    fig_combined.add_trace(go.Scatter(y=row, mode='lines', name=f\"Row {i + 1}\"))\n",
    "fig_combined.update_layout(\n",
    "    title=\"All Rows Combined\",\n",
    "    xaxis_title=\"Index\",\n",
    "    yaxis_title=\"Intensity\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Save the combined graph\n",
    "combined_output_path = output_dir + \"all_rows_combined_graph.html\"\n",
    "fig_combined.write_html(combined_output_path)\n",
    "print(f\"Saved combined interactive graph as {combined_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f086367b-0ad6-469e-99d3-1856aabe8e96",
   "metadata": {},
   "source": [
    "make the CFUs data from matlab as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316dc39-0afc-4f00-82f1-a0a7b4ef70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus = pd.DataFrame(scipy.io.loadmat(r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\All_CFUs.mat')['All_CFUs'])\n",
    "df_all_cfus_df = pd.DataFrame(scipy.io.loadmat(r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\All_CFUs_df.mat')['All_cfu_df'])\n",
    "df_all_cfus = df_trans_ren(df_all_cfus, 'CFU_')\n",
    "df_all_cfus_df = df_trans_ren(df_all_cfus_df, 'CFU_DF_')\n",
    "df_all_cfus_bg_corr = df_all_cfus-110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610c3068-36da-44c5-b118-a59316131e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus_baseline = calculate_baseline(df_all_cfus, sigma=10, deg=5)\n",
    "df_all_cfus_df_baseline = calculate_baseline(df_all_cfus_df, sigma=10, deg=5)\n",
    "df_all_cfus_bg_corr_baseline = calculate_baseline(df_all_cfus_bg_corr, sigma=10, deg=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f792e9f-1479-43d0-8011-2c4b9e5c542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus_bg_corr_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be24e64-cc4c-4fb2-8b20-a19cf6f68d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus_bg_corr_df =pd.DataFrame()\n",
    "for col in df_all_cfus_bg_corr.columns:\n",
    "    df_all_cfus_bg_corr_df[col] = (df_all_cfus_bg_corr[col]-df_all_cfus_bg_corr_baseline[col])/df_all_cfus_bg_corr_baseline[col]\n",
    "\n",
    "df_all_cfus_bg_corr_df_baseline = calculate_baseline(df_all_cfus_bg_corr_df, sigma=10, deg=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5a5c47-9bf6-45b8-9f29-b7449e147f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_cfus_bg_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbff63c-4466-411f-a279-a72921afe0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save(df_all_cfus_bg_corr, df_all_cfus_bg_corr_baseline, link_save + '\\corrected_baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbfe621-91d6-45f7-9427-ec22379dbc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_save(df_all_cfus_bg_corr_df, df_all_cfus_bg_corr_df_baseline, link_save + '\\corrected_df_baseline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a4cf62-799a-4caa-9fd5-25245ce938f8",
   "metadata": {},
   "source": [
    "data from tif file through masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a11786-58de-4a5c-b02a-a4502ce55bbc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Peak detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d65ac9-2e94-49fe-aff9-ac3f6080c7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices_df_aqua, peak_counts_df_aqua = detect_peaks(\n",
    "    df=df_all_cfus_df,\n",
    "    height=0.1,        # Minimum height of peaks (adjust as needed)\n",
    "    prominence=0.08,   # Minimum prominence of peaks\n",
    "    distance=30        # Minimum distance between peaks\n",
    ")\n",
    "\n",
    "print(peak_counts_df_aqua)\n",
    "plot_peaks(df_all_cfus_df, peak_indices_df_aqua, link_save + '\\CFU_Peaks_fromaqua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecddb0a-e009-4f12-b26e-23460f9a2699",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices, peak_counts_df = detect_peaks(\n",
    "    df=df_all_cfus_bg_corr_df,\n",
    "    height=0.1,        # Minimum height of peaks (adjust as needed)\n",
    "    prominence=0.08,   # Minimum prominence of peaks\n",
    "    distance=30        # Minimum distance between peaks\n",
    ")\n",
    "\n",
    "print(peak_counts_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4a442-9416-4439-8ca5-c274fec3940c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_peaks(df_all_cfus_bg_corr_df, peak_indices, link_save + '\\CFU_Peaks')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbabcdc7-550c-4945-92ea-692303c5fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\CFU_Smoothed_Peaks\"\n",
    "peak_indices, smoothed_data_dict, peak_counts_df = detect_peaks_on_smoothed_data(\n",
    "    df=df_all_cfus_bg_corr_df,  # Replace with your DataFrame\n",
    "    sigma=2,\n",
    "    height=0.1,\n",
    "    prominence=0.08,\n",
    "    distance=30\n",
    ")\n",
    "plot_peaks_on_smoothed_data(df_all_cfus_bg_corr_df, smoothed_data_dict, peak_indices, output_dir)\n",
    "peak_counts_df.to_csv(os.path.join(output_dir, \"peak_counts.csv\"))\n",
    "np.save(os.path.join(output_dir, \"peak_indices.npy\"), peak_indices)\n",
    "print(f\"Peak counts saved to {os.path.join(output_dir, 'peak_counts.csv')}\")\n",
    "print(f\"Peak indices saved to {os.path.join(output_dir, 'peak_indices.npy')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe5aff-335e-4ada-8772-ac43164aa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiff_file = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop4_1.tif\"\n",
    "mask_folder = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\Masks\"\n",
    "output_csv = link_save + \"\\intensity_data.csv\"\n",
    "output_dir = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\Save\\from_tif_dff\"\n",
    "\n",
    "cropped_tiff_file = r\"E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop4_1_cropped_file.tiff\"\n",
    "with tiff.TiffFile(tiff_file) as tif:\n",
    "    tiff_data = tif.asarray()\n",
    "print(f\"Original TIFF shape: {tiff_data.shape}\")\n",
    "tiff_data_cropped = crop_tiff_dimensions(tiff_data, crop_pixels=5)\n",
    "print(f\"Cropped TIFF shape: {tiff_data_cropped.shape}\")\n",
    "\n",
    "tiff.imwrite(cropped_tiff_file, tiff_data_cropped)\n",
    "print(f\"Cropped TIFF saved to {cropped_tiff_file}\")\n",
    "\n",
    "intensity_data = calculate_intensities(cropped_tiff_file, mask_folder, output_csv)\n",
    "intensity_data_corr = pd.DataFrame()\n",
    "for col in intensity_data.columns:\n",
    "    intensity_data_corr[col] = intensity_data[col] - intensity_data[col].min() +50\n",
    "dff_data = calculate_dff(intensity_data_corr)\n",
    "peak_indices, peak_counts_df = detect_peaks(dff_data, height=0.1, prominence=0.05, distance=20)\n",
    "plot_dff_and_peaks(dff_data, peak_indices, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f32e53-7b1c-401d-b3b9-8a11e0782cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_indices, peak_counts_df = detect_peaks(\n",
    "    df=dff_data,\n",
    "    height=0.1,        # Minimum height of peaks (adjust as needed)\n",
    "    prominence=0.1,   # Minimum prominence of peaks\n",
    "    distance=50        # Minimum distance between peaks\n",
    ")\n",
    "\n",
    "print(peak_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584674b8-c55c-482c-844d-c90adbffcb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 30.0  # Example: 30 frames per second\n",
    "all_peaks = []\n",
    "for roi, indices in peak_indices.items():\n",
    "    all_peaks.extend(indices)\n",
    "peak_times = np.array(all_peaks) / frame_rate\n",
    "time_bins = np.arange(0, peak_times.max() + 1, 1)  # From 0 to max peak time, in 1-second bins\n",
    "peak_counts, bin_edges = np.histogram(peak_times, bins=time_bins)\n",
    "density_df = pd.DataFrame({\n",
    "    \"Time (s)\": bin_edges[:-1],  # Start of each bin\n",
    "    \"Peak Density\": peak_counts\n",
    "})\n",
    "plt.bar(density_df[\"Time (s)\"], density_df[\"Peak Density\"], width=1, align='edge', color='blue', alpha=0.7)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Peak Density (Peaks per Second)\")\n",
    "plt.title(\"Density of Detected Peaks per Second\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d8b8a1-ab9d-47a1-bb05-b59a55611ceb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Get masks from mat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdf80d1-4654-4f90-b377-e68a514a2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_folder = r'E:\\Data\\241105_CM006\\unit4'\n",
    "link_file_mat = r'E:\\Data\\241105_CM006\\unit4\\unit4_32_crop_2_AQuA2.mat'\n",
    "mat = scipy.io.loadmat(link_folder_cm006_unit4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc379387-3aa8-43b5-9613-05007bf899c8",
   "metadata": {},
   "source": [
    "mat['cfuInfo1'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50471fc-2143-4afb-828d-d3a19dd1cd08",
   "metadata": {},
   "source": [
    "mat.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e7395-f418-4394-9fb1-e7654fcf25af",
   "metadata": {},
   "source": [
    "list(mat.keys())[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b844d33-21f1-4e95-a158-ff8991bd9446",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_test = {}\n",
    "mask_name = 'Mask_'\n",
    "for i in range(13):\n",
    "    df_test[i] = Image.fromarray((mat['cfuInfo1'][i][2] / np.max( mat['cfuInfo1'][i][2]) * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82444e5-534a-4887-a14d-4b1f984a7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(link_file_mat)\n",
    "cfu_to_tif_global(link_file_mat, link_save, list(mat.keys())[3], 2)\n",
    "pd_data, pd_data_df = get_data_global(link_file_mat, link_folder + '\\Save', list(mat.keys())[3])\n",
    "pd_data_df = pd.DataFrame(pd_data_df)\n",
    "pd_data = pd.DataFrame(pd_data)\n",
    "pd_data_corr = pd_data-110\n",
    "pd_data_corr_baseline = calculate_baseline(pd_data_corr, sigma=10, deg=5)\n",
    "pd_data_corr_df =pd.DataFrame()\n",
    "for col in pd_data_corr_baseline .columns:\n",
    "    pd_data_corr_df[col] = (pd_data_corr[col]-pd_data_corr_baseline[col])/pd_data_corr_baseline[col]\n",
    "\n",
    "pd_data_corr_df_baselinetocheck = calculate_baseline(pd_data_corr_df, sigma=10, deg=5)\n",
    "plot_and_save(pd_data_corr_df, pd_data_corr_df_baselinetocheck, link_folder + '\\Save' + '\\corrected_baseline')\n",
    "peak_indices_df, peak_counts_df = detect_peaks(\n",
    "    df=pd_data_corr_df,\n",
    "    height=0.1,        # Minimum height of peaks (adjust as needed)\n",
    "    prominence=0.08,   # Minimum prominence of peaks\n",
    "    distance=30        # Minimum distance between peaks\n",
    ")\n",
    "\n",
    "print(peak_counts_df)\n",
    "plot_peaks(pd_data_corr_df, peak_indices_df, link_folder + '\\Save' + '\\CFU_Peaks_calc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23acacd8-9ffe-4519-90b4-9fff12b02d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd_data_corr_df\n",
    "peak_indices, smoothed_data, peak_counts = detect_peaks_on_smoothed_data(df, fs=30.9, cutoff=5, height=0.1, prominence=0.2, distance=15)\n",
    "print(peak_counts)\n",
    "time = np.linspace(0, len(df[cfu]) / 30.9, len(df[cfu]))\n",
    "cfu = \"Mask_1\"\n",
    "original_data = df[cfu].values\n",
    "smoothed = smoothed_data[cfu]\n",
    "peaks = peak_indices[cfu]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=original_data, mode='lines', name=\"Original Data\", line=dict(color=\"blue\", width=1)))\n",
    "fig.add_trace(go.Scatter(x=time, y=smoothed, mode='lines', name=\"Smoothed Data\", line=dict(color=\"green\", width=2)))\n",
    "fig.add_trace(go.Scatter(x=time[peaks], y=smoothed[peaks], mode='markers', name=\"Peaks\", marker=dict(color='red', size=8)))\n",
    "fig.update_layout(\n",
    "    title=f\"Peaks for {cfu}\",\n",
    "    xaxis_title=\"Time (s)\",\n",
    "    yaxis_title=\"Intensity\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=1, y=1)\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e867b-607f-4913-96b3-5a40bfad9aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfu = \"Mask_1\"\n",
    "original_data = df[cfu].values\n",
    "smoothed = smoothed_data[cfu]\n",
    "peaks = peak_indices[cfu]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=time, y=original_data, mode='lines', name=\"Original Data\", line=dict(color=\"blue\", width=1)))\n",
    "fig.add_trace(go.Scatter(x=time, y=smoothed, mode='lines', name=\"Smoothed Data\", line=dict(color=\"green\", width=2)))\n",
    "fig.add_trace(go.Scatter(x=time[peaks], y=smoothed[peaks], mode='markers', name=\"Peaks\", marker=dict(color='red', size=8)))\n",
    "fig.update_layout(\n",
    "    title=f\"Peaks for {cfu}\",\n",
    "    xaxis_title=\"Time (s)\",\n",
    "    yaxis_title=\"Intensity\",\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(x=1, y=1)\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8dd48c-ed43-414b-80a2-d63250e5380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop2_32\\Save' + '\\CFU_Peaks_calc_smooth'\n",
    "plot_peaks_on_smoothed_data_with_baseline(df, smoothed_data, peak_indices, pd_data_corr_df_baselinetocheck, output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc742f55-5230-4cbb-b98e-e76b302d5b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_peak_density_per_cfu(peak_indices, fs=30.9, output_dir=r'E:\\CM006_uni4_test_matlab_aqua_CFUs\\unit4_crop2_32\\Save' + '\\CFU_Peaks_dencity' ,bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e35d7e-fec3-49d3-baf5-36dd2fa1f05f",
   "metadata": {},
   "source": [
    "# Script to run for the data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ac6b9-6aa3-479d-a3a4-fc5c7392e181",
   "metadata": {},
   "source": [
    "How to use?\n",
    "\n",
    "- get the tiff files from anywhere, better - suite2p corrected\n",
    "- convert to 32 bit through ImageJ, crop to get the final size less than 4 Gb\n",
    "- save the final file\n",
    "- recommended to create a folder to place the file\n",
    "- run the AQuA2 in Matlab (no excluded borders, set the fps etc.), threshold on 2-3, test a few)\n",
    "- run CFU and choose the CFUs that you need\n",
    "- load the traces to the workspace and save the .mat file with the masks and traces to the previously created folder\n",
    "\n",
    "Then:\n",
    "- set up the standard conda env and install all necessary libs\n",
    "- run the imports\n",
    "- run the functions\n",
    "- create the cell with the links to the .mat file and where to save the outputs\n",
    "- run the cell with links and the script cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501ef1a0-ed55-4124-afe5-3e53ce1a28f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM006 Unit4 crop 2\n",
    "link_folder = r'E:\\Data\\241105_CM006\\unit4'\n",
    "link_file_mat = r'E:\\Data\\241105_CM006\\unit4\\unit4_32_crop_2_AQuA2.mat'\n",
    "link_save = r'E:\\Data\\241105_CM006\\unit4\\Save'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddd8ea3-55f2-483a-af48-2edbb666f21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM005 Unit10 \n",
    "link_folder = r'E:\\CM005_unit10'\n",
    "link_file_mat = r'E:\\CM005_unit10\\cm005_unit10.mat'\n",
    "link_save = r'E:\\CM005_unit10\\Save'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d94a9-79c6-4db1-8e69-92d28d662d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CM006 Unit8 \n",
    "link_folder = r'E:\\Data\\241105_CM006\\unit8'\n",
    "link_file_mat = r'E:\\Data\\241105_CM006\\unit8\\unit8_32_bottomhalf.mat'\n",
    "link_save = r'E:\\Data\\241105_CM006\\unit8\\Save'\n",
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fdd30b-5e56-4db1-8770-5e64f2ea8b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat(link_file_mat)\n",
    "cfu_to_tif_global(link_file_mat, link_save, list(mat.keys())[3], 2)\n",
    "pd_data, pd_data_df = get_data_global(link_file_mat, link_save, list(mat.keys())[3])\n",
    "pd_data_df = pd.DataFrame(pd_data_df)\n",
    "pd_data = pd.DataFrame(pd_data)\n",
    "pd_data_corr = pd_data-110\n",
    "pd_data_corr_baseline = calculate_baseline(pd_data_corr, sigma=sigma_value, deg = deg_value)\n",
    "pd_data_corr_df =pd.DataFrame()\n",
    "for col in pd_data_corr_baseline .columns:\n",
    "    pd_data_corr_df[col] = (pd_data_corr[col]-pd_data_corr_baseline[col])/pd_data_corr_baseline[col]\n",
    "pd_data_corr_df_baselinetocheck = calculate_baseline(pd_data_corr_df, sigma=sigma_value, deg = deg_value)\n",
    "plot_and_save(pd_data_corr_df, pd_data_corr_df_baselinetocheck, link_save + '\\corrected_baseline')\n",
    "output_dir = link_save + '\\CFU_Peaks_calc_smooth'\n",
    "peak_indices, smoothed_data, peak_counts = detect_peaks_on_smoothed_data(pd_data_corr_df, \n",
    "                                                                         fs=fs_value, \n",
    "                                                                         cutoff=cutoff_value, \n",
    "                                                                         height=height_value,        # Minimum height of peaks (adjust as needed)\n",
    "                                                                         prominence=prominence_value,   # Minimum prominence of peaks\n",
    "                                                                         distance=distance_value )\n",
    "print(peak_counts)\n",
    "plot_peaks_on_smoothed_data_with_baseline(pd_data_corr_df, \n",
    "                                          smoothed_data, peak_indices, \n",
    "                                          pd_data_corr_df_baselinetocheck, \n",
    "                                          link_save + '\\CFU_Peaks_calc_smooth', fs_value)\n",
    "plot_peak_density_per_cfu(peak_indices, fs=fs_value, output_dir=link_save + '\\CFU_Peaks_dencity')\n",
    "save_cfu_analysis_with_report_v2(\n",
    "    pd_data_corr_df, smoothed_data, pd_data_corr_df_baselinetocheck, peak_indices, link_save,\n",
    "    link_folder, link_file_mat, link_save,\n",
    "    sigma_value, deg_value, fs_value, height_value, prominence_value, distance_value\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fbde35-8357-4018-97e5-1cb9458202ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_value = 10\n",
    "deg_value = 5\n",
    "fs_value = 30.9\n",
    "height_value=0.2        # Minimum height of peaks (adjust as needed)\n",
    "prominence_value=0.1   # Minimum prominence of peaks\n",
    "distance_value=2\n",
    "cutoff_value = 5\n",
    "\n",
    "plot_combined_smoothed_and_peak_density(\n",
    "     pd_data_corr_df, smoothed_data, peak_indices, fps=fs_value, \n",
    "     height_value=height_value, prominence_value=prominence_value, distance_value=distance_value, sigma_value=sigma_value,\n",
    "     output_path=link_save + \"\\combined_plots\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852ae90-58af-49f7-866c-197c4d4c3f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
